{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\timmy\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import os, sys, math\n",
    "import config\n",
    "\n",
    "tf.set_random_seed(seed=1991)\n",
    "np.random.seed(seed=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('./data/dataset_kor/교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv', engine='python')\n",
    "raw_df = raw_df[config.test_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in config.kv_map.keys():\n",
    "#    print(key)\n",
    "    raw_df[key] = raw_df[key].apply(lambda x: config.kv_map[key][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.keep_prop = 0.7\n",
    "config.train_size = 22528\n",
    "config.cate_len = len(config.cate_cols)\n",
    "config.cont_len = len(config.cont_cols)\n",
    "config.cate_lens = [len(config.kv_map[k]) for k in config.cate_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = raw_df[:config.train_size]\n",
    "valid_df = raw_df[config.train_size:]\n",
    "\n",
    "# train_df = raw_df[len(raw_df)-config.train_size:]\n",
    "# valid_df = raw_df[:len(raw_df)-config.train_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_cate = train_df.loc[:,config.cate_cols]\n",
    "train_df_cont = train_df.loc[:,config.cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df_cate = valid_df.loc[:,config.cate_cols]\n",
    "valid_df_cont = valid_df.loc[:,config.cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=910919)\n",
    "config.vaild_drop_mask = np.random.rand(valid_df_cate.values.shape[0], valid_df_cate.values.shape[1])> (1- config.keep_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=3632)\n",
    "config.vaild_test_drop_mask = np.random.rand(valid_df_cate.values.shape[0], valid_df_cate.values.shape[1])> (1- config.keep_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dir_ckpt = '.\\\\ckpt'\n",
    "config.path_ckpt = os.path.join(config.dir_ckpt, 'best.ckpt')\n",
    "config.l1_size = 128\n",
    "config.l2_size = 64\n",
    "config.cate_out_size = sum(config.cate_lens)\n",
    "config.cont_out_size = config.cont_len\n",
    "config.epochs = 600\n",
    "config.batch_size = 64\n",
    "\n",
    "train_step = math.ceil(len(train_df)/ config.batch_size)\n",
    "valid_step = math.ceil(len(valid_df)/ config.batch_size)\n",
    "\n",
    "os.makedirs(config.dir_ckpt , exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(config):\n",
    "    tf.reset_default_graph()\n",
    "    inp_cate = tf.placeholder(dtype=tf.int32, shape=[None, config.cate_len], name='categorical_input_layer')\n",
    "    inp_cont = tf.placeholder(dtype=tf.float32, shape=[None, config.cont_len], name='continuous_input_layer')\n",
    "    inp_cate_y = tf.placeholder(dtype=tf.int32, shape=[None, config.cate_len], name='categorical_input_y_layer')\n",
    "    inp_cont_y = tf.placeholder(dtype=tf.float32, shape=[None, config.cont_len], name='continuous_input_y_layer')\n",
    "\n",
    "    cate_oh = [tf.one_hot(inp_cate[:, i], depth=config.cate_lens[i]) for i in range(len(config.cate_cols))]\n",
    "    cate_oh_y = [tf.one_hot(inp_cate_y[:, i], depth=config.cate_lens[i]) for i in range(len(config.cate_cols))]\n",
    "    concat_cate_y = tf.concat(cate_oh_y, axis=-1)\n",
    "    \n",
    "    concat_cate = tf.concat(cate_oh, axis=-1)\n",
    "    concat_all = tf.concat([concat_cate, inp_cont], axis=-1)\n",
    "    \n",
    "    l1 = tf.contrib.layers.fully_connected(concat_all, config.l1_size)\n",
    "#    l2 = tf.contrib.layers.fully_connected(l1, config.l1_size)\n",
    "    \n",
    "    logit_cates = [tf.contrib.layers.fully_connected(l1, l, activation_fn = None) for l in config.cate_lens]\n",
    "    logit_cont = tf.contrib.layers.fully_connected(l1, config.cont_out_size, activation_fn = None)\n",
    "    \n",
    "    pred_cates = [tf.nn.softmax(logit) for logit in logit_cates]\n",
    "    pred_cate = tf.concat(pred_cates, axis=-1)\n",
    "    pred_cont = tf.nn.softmax(logit_cont)\n",
    "    \n",
    "#    loss_cate_op = tf.losses.mean_squared_error(concat_cate_y, pred_cate)\n",
    "    loss_cate_ops = [tf.reduce_sum(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=inp_cate_y[:,idx], logits=logit_cates[idx])) for idx in range(11)]\n",
    "    loss_cate_op = tf.reduce_sum(loss_cate_ops, axis=-1)\n",
    "\n",
    "    loss_cont_op = tf.losses.mean_squared_error(inp_cont_y, pred_cont)\n",
    "    loss_op = loss_cate_op\n",
    "    #+ loss_cont_op\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)\n",
    "    train_op = optimizer.minimize(loss_op)\n",
    "    \n",
    "    return loss_op, train_op, inp_cate, inp_cont, inp_cate_y, inp_cont_y, pred_cate, pred_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = build_model(config)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_session(sess, max_step, datas, config, epoch, mode=1):\n",
    "    total_loss = 0.0\n",
    "    loss_op, train_op, inp_cate, inp_cont, inp_cate_y, inp_cont_y, pred_cate, pred_cont = mdl\n",
    "\n",
    "    #train\n",
    "    if mode ==1:\n",
    "        drop_mask = np.random.rand(datas[0].values.shape[0], datas[0].values.shape[1])> (1- config.keep_prop)\n",
    "        droped_cate = datas[0].values * drop_mask\n",
    "        \n",
    "        for step in range(max_step):\n",
    "            start_idx = step * config.batch_size\n",
    "            loss_, _ = sess.run([loss_op, train_op], feed_dict = {inp_cate:droped_cate[start_idx:start_idx+config.batch_size], \n",
    "                                                                  inp_cont:datas[1].values[start_idx:start_idx+config.batch_size], \n",
    "                                                                  inp_cate_y:datas[0].values[start_idx:start_idx+config.batch_size],\n",
    "                                                                  inp_cont_y:datas[1].values[start_idx:start_idx+config.batch_size]})\n",
    "            \n",
    "#            print(loss_)\n",
    "            total_loss += loss_\n",
    "        total_loss /= max_step\n",
    "        return total_loss \n",
    "    \n",
    "    #validation\n",
    "    elif mode == 2:\n",
    "        droped_valid_cate = datas[0].values * config.vaild_drop_mask\n",
    "        \n",
    "        for step in range(max_step):\n",
    "            start_idx = step * config.batch_size\n",
    "            loss_ = sess.run(loss_op, feed_dict = {inp_cate:droped_valid_cate[start_idx:start_idx+config.batch_size], \n",
    "                                                   inp_cont:datas[1].values[start_idx:start_idx+config.batch_size], \n",
    "                                                   inp_cate_y:datas[0].values[start_idx:start_idx+config.batch_size],\n",
    "                                                   inp_cont_y:datas[1].values[start_idx:start_idx+config.batch_size]})\n",
    "            \n",
    "            total_loss += loss_\n",
    "        total_loss /= max_step\n",
    "        return total_loss \n",
    "    \n",
    "    #valid_test\n",
    "    elif mode == 3:\n",
    "        droped_valid_cate = datas[0].values * config.vaild_test_drop_mask\n",
    "        preds_cate, preds_cont = [], []\n",
    "        for step in range(max_step):\n",
    "            start_idx = step * config.batch_size\n",
    "            pred_cate_, pred_cont_ = sess.run([pred_cate, pred_cont], \n",
    "                                              feed_dict = {inp_cate:droped_valid_cate[start_idx:start_idx+config.batch_size], \n",
    "                                                           inp_cont:datas[1].values[start_idx:start_idx+config.batch_size]})\n",
    "            preds_cate.append(pred_cate_)\n",
    "            preds_cont.append(pred_cont_)\n",
    "            \n",
    "        return preds_cate, preds_cont\n",
    "    \n",
    "    else:\n",
    "        print('error')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\t1070.1061467257414\n",
      "Train_loss : 1070.106147\tValid_loss : 733.772060\tSaved\n",
      "Epoch : 2\t633.4662672389637\n",
      "Train_loss : 633.466267\tValid_loss : 539.211455\tSaved\n",
      "Epoch : 3\t490.59025851163\n",
      "Train_loss : 490.590259\tValid_loss : 447.232726\tSaved\n",
      "Epoch : 4\t417.1036650917747\n",
      "Train_loss : 417.103665\tValid_loss : 392.022780\tSaved\n",
      "Epoch : 5\t369.46913892572576\n",
      "Train_loss : 369.469139\tValid_loss : 355.940692\tSaved\n",
      "Epoch : 6\t335.4026738947088\n",
      "Train_loss : 335.402674\tValid_loss : 330.145559\tSaved\n",
      "Epoch : 7\t314.40616403926504\n",
      "Train_loss : 314.406164\tValid_loss : 312.230476\tSaved\n",
      "Epoch : 8\t297.05015507611364\n",
      "Train_loss : 297.050155\tValid_loss : 297.827835\tSaved\n",
      "Epoch : 9\t284.5749568939209\n",
      "Train_loss : 284.574957\tValid_loss : 286.191349\tSaved\n",
      "Epoch : 10\t271.0269792730158\n",
      "Train_loss : 271.026979\tValid_loss : 278.503057\tSaved\n",
      "Epoch : 11\t266.8626154119318\n",
      "Train_loss : 266.862615\tValid_loss : 272.647685\tSaved\n",
      "Epoch : 12\t260.52639350024134\n",
      "Train_loss : 260.526394\tValid_loss : 267.003379\tSaved\n",
      "Epoch : 13\t255.07673757726496\n",
      "Train_loss : 255.076738\tValid_loss : 264.256611\tSaved\n",
      "Epoch : 14\t249.8304989121177\n",
      "Train_loss : 249.830499\tValid_loss : 259.776126\tSaved\n",
      "Epoch : 15\t247.6459886377508\n",
      "Train_loss : 247.645989\tValid_loss : 257.452347\tSaved\n",
      "Epoch : 16\t246.2370116927407\n",
      "Train_loss : 246.237012\tValid_loss : 255.431572\tSaved\n",
      "Epoch : 17\t243.33072046800092\n",
      "Train_loss : 243.330720\tValid_loss : 254.694162\tSaved\n",
      "Epoch : 18\t241.90677777203646\n",
      "Train_loss : 241.906778\tValid_loss : 251.796339\tSaved\n",
      "Epoch : 19\t240.99337642843074\n",
      "Train_loss : 240.993376\tValid_loss : 251.653773\tSaved\n",
      "Epoch : 20\t238.07370580326426\n",
      "Train_loss : 238.073706\tValid_loss : 250.956032\tSaved\n",
      "Epoch : 21\t238.86635958064687\n",
      "Train_loss : 238.866360\tValid_loss : 249.139404\tSaved\n",
      "Epoch : 22\t238.302105513486\n",
      "Train_loss : 238.302106\tValid_loss : 247.903860\tSaved\n",
      "Epoch : 23\t235.65316291288897\n",
      "Train_loss : 235.653163\tValid_loss : 247.605882\tSaved\n",
      "Epoch : 24\t234.9672545519742\n",
      "Train_loss : 234.967255\tValid_loss : 248.060830\tNo Saved\n",
      "Epoch : 25\t235.5380153656006\n",
      "Train_loss : 235.538015\tValid_loss : 246.508548\tSaved\n",
      "Epoch : 26\t233.48189635710284\n",
      "Train_loss : 233.481896\tValid_loss : 246.798238\tNo Saved\n",
      "Epoch : 27\t233.80970395695078\n",
      "Train_loss : 233.809704\tValid_loss : 246.254042\tSaved\n",
      "Epoch : 28\t232.7879424528642\n",
      "Train_loss : 232.787942\tValid_loss : 245.336866\tSaved\n",
      "Epoch : 29\t234.4170801856301\n",
      "Train_loss : 234.417080\tValid_loss : 245.181559\tSaved\n",
      "Epoch : 30\t230.72648672624067\n",
      "Train_loss : 230.726487\tValid_loss : 245.508197\tNo Saved\n",
      "Epoch : 31\t233.34187165173617\n",
      "Train_loss : 233.341872\tValid_loss : 244.428786\tSaved\n",
      "Epoch : 32\t230.39576083963567\n",
      "Train_loss : 230.395761\tValid_loss : 243.701590\tSaved\n",
      "Epoch : 33\t231.17817297848788\n",
      "Train_loss : 231.178173\tValid_loss : 244.233004\tNo Saved\n",
      "Epoch : 34\t232.36026967655528\n",
      "Train_loss : 232.360270\tValid_loss : 243.878102\tNo Saved\n",
      "Epoch : 35\t233.4666095646945\n",
      "Train_loss : 233.466610\tValid_loss : 242.969463\tSaved\n",
      "Epoch : 36\t229.73664665222168\n",
      "Train_loss : 229.736647\tValid_loss : 243.161198\tNo Saved\n",
      "Epoch : 37\t227.2942674376748\n",
      "Train_loss : 227.294267\tValid_loss : 243.545179\tNo Saved\n",
      "Epoch : 38\t230.42513539574364\n",
      "Train_loss : 230.425135\tValid_loss : 243.038154\tNo Saved\n",
      "Epoch : 39\t231.16927467692983\n",
      "Train_loss : 231.169275\tValid_loss : 243.333891\tNo Saved\n",
      "Epoch : 40\t231.8581168868325\n",
      "Train_loss : 231.858117\tValid_loss : 242.801865\tSaved\n",
      "Epoch : 41\t232.15636712854558\n",
      "Train_loss : 232.156367\tValid_loss : 242.863668\tNo Saved\n",
      "Epoch : 42\t228.69707172567195\n",
      "Train_loss : 228.697072\tValid_loss : 242.467859\tSaved\n",
      "Epoch : 43\t230.19896385886452\n",
      "Train_loss : 230.198964\tValid_loss : 244.255332\tNo Saved\n",
      "Epoch : 44\t229.29421997070312\n",
      "Train_loss : 229.294220\tValid_loss : 242.883678\tNo Saved\n",
      "Epoch : 45\t230.96205030788076\n",
      "Train_loss : 230.962050\tValid_loss : 242.419956\tSaved\n",
      "Epoch : 46\t229.37080400640315\n",
      "Train_loss : 229.370804\tValid_loss : 242.774920\tNo Saved\n",
      "Epoch : 47\t227.11513510617343\n",
      "Train_loss : 227.115135\tValid_loss : 243.259071\tNo Saved\n",
      "Epoch : 48\t228.9741510477933\n",
      "Train_loss : 228.974151\tValid_loss : 242.943791\tNo Saved\n",
      "Epoch : 49\t230.79366267811167\n",
      "Train_loss : 230.793663\tValid_loss : 242.858411\tNo Saved\n",
      "Epoch : 50\t230.81273789839312\n",
      "Train_loss : 230.812738\tValid_loss : 241.593058\tSaved\n",
      "Epoch : 51\t225.48397985371676\n",
      "Train_loss : 225.483980\tValid_loss : 242.637166\tNo Saved\n",
      "Epoch : 52\t228.99090654199773\n",
      "Train_loss : 228.990907\tValid_loss : 242.592185\tNo Saved\n",
      "Epoch : 53\t227.60477568886498\n",
      "Train_loss : 227.604776\tValid_loss : 242.731172\tNo Saved\n",
      "Epoch : 54\t231.74994399330834\n",
      "Train_loss : 231.749944\tValid_loss : 242.294646\tNo Saved\n",
      "Epoch : 55\t227.99987411499023\n",
      "Train_loss : 227.999874\tValid_loss : 243.140213\tNo Saved\n",
      "Epoch : 56\t226.30434096943247\n",
      "Train_loss : 226.304341\tValid_loss : 242.979071\tNo Saved\n",
      "Epoch : 57\t225.6834124218334\n",
      "Train_loss : 225.683412\tValid_loss : 242.398326\tNo Saved\n",
      "Epoch : 58\t225.32277527722445\n",
      "Train_loss : 225.322775\tValid_loss : 241.932454\tNo Saved\n",
      "Epoch : 59\t229.61164569854736\n",
      "Train_loss : 229.611646\tValid_loss : 242.268864\tNo Saved\n",
      "Epoch : 60\t227.95717282728717\n",
      "Train_loss : 227.957173\tValid_loss : 243.367456\tNo Saved\n",
      "Epoch : 61\t227.69343181089923\n",
      "Train_loss : 227.693432\tValid_loss : 242.386586\tNo Saved\n",
      "Epoch : 62\t230.44124694304034\n",
      "Train_loss : 230.441247\tValid_loss : 242.889839\tNo Saved\n",
      "Epoch : 63\t224.62848021767357\n",
      "Train_loss : 224.628480\tValid_loss : 243.444171\tNo Saved\n",
      "Epoch : 64\t225.93041532689875\n",
      "Train_loss : 225.930415\tValid_loss : 243.137943\tNo Saved\n",
      "Epoch : 65\t229.0185240832242\n",
      "Train_loss : 229.018524\tValid_loss : 242.890437\tNo Saved\n",
      "Epoch : 66\t226.82438031109896\n",
      "Train_loss : 226.824380\tValid_loss : 242.921917\tNo Saved\n",
      "Epoch : 67\t225.72469026392156\n",
      "Train_loss : 225.724690\tValid_loss : 241.942693\tNo Saved\n",
      "Epoch : 68\t225.95024026523936\n",
      "Train_loss : 225.950240\tValid_loss : 243.284086\tNo Saved\n",
      "Epoch : 69\t226.26337870684537\n",
      "Train_loss : 226.263379\tValid_loss : 242.804704\tNo Saved\n",
      "Epoch : 70\t228.68042599071157\n",
      "Train_loss : 228.680426\tValid_loss : 242.279841\tNo Saved\n",
      "Epoch : 71\t226.43281932310626\n",
      "Train_loss : 226.432819\tValid_loss : 242.465949\tNo Saved\n",
      "Epoch : 72\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e2623051578e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mtrn_total_loss_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_df_cate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df_cont\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_total_loss_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train_loss : {:.6f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_total_loss_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-0fcf08ee8855>\u001b[0m in \u001b[0;36mrun_session\u001b[1;34m(sess, max_step, datas, config, epoch, mode)\u001b[0m\n\u001b[0;32m     13\u001b[0m                                                                   \u001b[0minp_cont\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                                                   \u001b[0minp_cate_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                                                                   inp_cont_y:datas[1].values[start_idx:start_idx+config.batch_size]})\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#            print(loss_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timmy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timmy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timmy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timmy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timmy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timmy\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =======================================================================================\n",
    "# run session\n",
    "with tf.Session() as sess:\n",
    "    tf.set_random_seed(seed=1991)\n",
    "    np.random.seed(seed=1991)\n",
    "    sess.run(init)\n",
    "    min_val_loss = 9999\n",
    "    \n",
    "    for epoch in range(1, config.epochs+1):\n",
    "        print(\"Epoch : {}\".format(epoch), end='\\t')\n",
    "        \n",
    "        #train\n",
    "        trn_total_loss_ = run_session(sess, train_step, [train_df_cate, train_df_cont], config, epoch, mode=1)\n",
    "        print(trn_total_loss_)\n",
    "        print(\"Train_loss : {:.6f}\".format(trn_total_loss_), end = '\\t')\n",
    "        \n",
    "        #valid\n",
    "        val_total_loss_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, epoch, mode=2)\n",
    "        print(\"Valid_loss : {:.6f}\".format(val_total_loss_), end = '\\t')\n",
    "        \n",
    "        if val_total_loss_ < min_val_loss:\n",
    "            saver.save(sess, config.path_ckpt)\n",
    "            min_val_loss = val_total_loss_\n",
    "            print(\"Saved\")\n",
    "        else:\n",
    "            print(\"No Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best.ckpt\n"
     ]
    }
   ],
   "source": [
    "# =======================================================================================\n",
    "# valid_test\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, config.path_ckpt)\n",
    "    preds_cate_, preds_cont_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, epoch, mode=3)\n",
    "    \n",
    "    preds_cate_ = np.concatenate(preds_cate_)\n",
    "    preds_cont_ = np.concatenate(preds_cont_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_tst_score : 0.999429\n"
     ]
    }
   ],
   "source": [
    "pred_args = []\n",
    "for p_ in preds_cate_:\n",
    "    start_idx = 0\n",
    "    pred_arg = []\n",
    "    for kl in config.cate_lens:\n",
    "        pred_arg.append(np.argmax(p_[start_idx: start_idx+kl]))\n",
    "        start_idx += kl\n",
    "    pred_args.append(pred_arg)\n",
    "\n",
    "pred_args_np = np.array(pred_args)\n",
    "\n",
    "val_test_ijv = []\n",
    "for i, vs in enumerate(config.vaild_test_drop_mask):\n",
    "    for j, v in enumerate(vs):\n",
    "        if v:\n",
    "            val_test_ijv.append([i,j,valid_df_cate.values[i,j]])    \n",
    "\n",
    "sum_true = 0\n",
    "for ijv in val_test_ijv:\n",
    "    i,j,v = ijv\n",
    "    sum_true+=(pred_args_np[i, j] == v)\n",
    "\n",
    "val_tst_score = sum_true/len(val_test_ijv)\n",
    "print(\"val_tst_score : {:6f}\".format(val_tst_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch : 500\tTrain_loss : 0.004380\tValid_loss : 0.004452\tSaved => 0.987826"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
