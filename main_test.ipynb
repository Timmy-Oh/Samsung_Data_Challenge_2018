{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\timmy\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is built...\n",
      "Predicting...\n",
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best1.ckpt\n",
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best2.ckpt\n",
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best3.ckpt\n",
      "Exproting...\n",
      "Output_File is Exported to C:\\Users\\timmy\\OneDrive\\GitHub\\Samsung_Data_Challenge_2018\\test_export\\test_export.csv\n",
      "Result_File is Exported to C:\\Users\\timmy\\OneDrive\\GitHub\\Samsung_Data_Challenge_2018\\test_export\\result.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import os, math\n",
    "import config\n",
    "\n",
    "from model_functions import build_model, run_session\n",
    "\n",
    "test_df = pd.read_csv('./data/test_kor.csv', engine='python')\n",
    "test_df = test_df[config.test_cols]\n",
    "config.test_cate_mask = test_df[config.cate_cols].isna().values\n",
    "config.test_cont_mask = test_df[config.cont_cols].isna().values\n",
    "\n",
    "test_df[config.cate_cols] = test_df[config.cate_cols].fillna('N')\n",
    "test_df[config.cont_cols] = test_df[config.cont_cols].fillna(-1)\n",
    "for key in config.kv_map.keys():\n",
    "    test_df[key] = test_df[key].apply(lambda x: config.kv_map[key][x])\n",
    "\n",
    "mdl = build_model(config)\n",
    "print(\"Model is built...\")\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=5)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "test_df_cate = test_df.loc[:,config.cate_cols]\n",
    "test_df_cont = test_df.loc[:,config.cont_cols]\n",
    "\n",
    "test_step = math.ceil(len(test_df)/ config.batch_size)\n",
    "\n",
    "# test\n",
    "print(\"Predicting...\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best1.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, test_step, [test_df_cate, test_df_cont], config, mdl, mode=4)\n",
    "\n",
    "    preds_cate_1 = np.concatenate(preds_cate_)\n",
    "    preds_cont_1 = np.concatenate(preds_cont_)\n",
    "\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best2.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, test_step, [test_df_cate, test_df_cont], config, mdl, mode=4)\n",
    "\n",
    "    preds_cate_2 = np.concatenate(preds_cate_)\n",
    "    preds_cont_2 = np.concatenate(preds_cont_)\n",
    "\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best3.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, test_step, [test_df_cate, test_df_cont], config, mdl, mode=4)\n",
    "\n",
    "    preds_cate_3 = np.concatenate(preds_cate_)\n",
    "    preds_cont_3 = np.concatenate(preds_cont_)\n",
    "\n",
    "preds_cate_ = (preds_cate_1 + preds_cate_2 + preds_cate_3)/3\n",
    "preds_cont_ = (preds_cont_1 + preds_cont_2 + preds_cont_3)/3\n",
    "\n",
    "\n",
    "#out\n",
    "print(\"Exproting...\")\n",
    "#cliping\n",
    "preds_cont_[preds_cont_<0] = 0.0\n",
    "\n",
    "# Categorical Vals Restore\n",
    "pred_args = []\n",
    "for p_ in preds_cate_:\n",
    "    start_idx = 0\n",
    "    pred_arg = []\n",
    "    for kl in config.cate_lens:\n",
    "        pred_arg.append(np.argmax(p_[start_idx: start_idx+kl]))\n",
    "        start_idx += kl\n",
    "    pred_args.append(pred_arg)\n",
    "pred_args_np = np.array(pred_args)   \n",
    "\n",
    "# Merge\n",
    "test_df[config.cate_cols] = config.test_cate_mask * pred_args_np + test_df[config.cate_cols].values * ((config.test_cate_mask - 1)*(-1))\n",
    "test_df[config.cont_cols] = config.test_cont_mask * preds_cont_  + test_df[config.cont_cols].values * ((config.test_cont_mask - 1)*(-1))\n",
    "\n",
    "for key in config.cate_cols:\n",
    "    test_df.loc[:,key] = test_df.loc[:,key].apply(lambda x: [k for k, v in config.kv_map[key].items() if v == x][0])\n",
    "\n",
    "# Export\n",
    "os.makedirs(config.dir_test, exist_ok=True)\n",
    "test_df.to_csv(config.path_test, encoding='cp949', index=False, columns=config.test_cols)\n",
    "print(\"Output_File is Exported to {}\".format(os.path.abspath(config.path_test)))\n",
    "\n",
    "df_test_out = pd.read_csv(config.path_test, encoding='cp949')\n",
    "df_result = pd.read_csv('./data/result_kor.csv', encoding='cp949')\n",
    "\n",
    "result_list = []\n",
    "for r, c in zip(df_result.행, df_result.열):\n",
    "    result_list.append(df_test_out.iloc[r-2][config.cols_dict[c]])\n",
    "\n",
    "df_result.값 = result_list\n",
    "df_result.to_csv(config.path_result, encoding='cp949', index=False)\n",
    "print(\"Result_File is Exported to {}\".format(os.path.abspath(config.path_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
