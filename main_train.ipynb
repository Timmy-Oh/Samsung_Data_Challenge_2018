{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is Ready...\n",
      "Model 1 is built...\n",
      "Model 1 is training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-674261501ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;31m#valid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[0mval_total_loss_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalid_df_cate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_df_cont\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\GitHub\\Samsung_Data_Challenge_2018\\model_functions.py\u001b[0m in \u001b[0;36mrun_session\u001b[1;34m(sess, max_step, datas, config, mdl, mode)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m                                                    \u001b[0minp_cate_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m                                                    inp_cont_y:datas[1].values[start_idx:start_idx+config.batch_size]})\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import os, math\n",
    "import config\n",
    "\n",
    "from model_functions import build_model, run_session\n",
    "\n",
    "os.makedirs(config.dir_ckpt , exist_ok=True)\n",
    "\n",
    "raw_df = pd.read_csv('./data/dataset_kor/교통사망사고정보/Kor_Train_교통사망사고정보(12.1~17.6).csv', engine='python')\n",
    "raw_df = raw_df[config.test_cols]\n",
    "\n",
    "for key in config.kv_map.keys():\n",
    "    raw_df[key] = raw_df[key].apply(lambda x: config.kv_map[key][x])\n",
    "\n",
    "for mdl_num in range(1,4):\n",
    "    if mdl_num == 1:\n",
    "        np.random.seed(seed=1000)\n",
    "        shuffle_idx = np.random.rand(len(raw_df)) \n",
    "        train_df = raw_df[shuffle_idx<= 0.85]\n",
    "        valid_df = raw_df[shuffle_idx > 0.85]\n",
    "\n",
    "    elif mdl_num == 2:\n",
    "        np.random.seed(seed=2000)\n",
    "        shuffle_idx = np.random.rand(len(raw_df)) \n",
    "        train_df = raw_df[shuffle_idx<= 0.85]\n",
    "        valid_df = raw_df[shuffle_idx > 0.85]\n",
    "\n",
    "    else:\n",
    "        train_df = raw_df[:config.train_size]\n",
    "        valid_df = raw_df[config.train_size:]\n",
    "    \n",
    "    \n",
    "    config.path_ckpt = os.path.join(config.dir_ckpt, 'best{}.ckpt'.format(mdl_num))\n",
    "\n",
    "    train_df_cate = train_df.loc[:,config.cate_cols]\n",
    "    train_df_cont = train_df.loc[:,config.cont_cols]\n",
    "\n",
    "    valid_df_cate = valid_df.loc[:,config.cate_cols]\n",
    "    valid_df_cont = valid_df.loc[:,config.cont_cols]\n",
    "\n",
    "    np.random.seed(seed=9)\n",
    "    config.vaild_drop_mask = np.random.rand(valid_df_cate.values.shape[0], valid_df_cate.values.shape[1])>(1- config.keep_prop)\n",
    "    config.vaild_cont_mask = np.random.rand(valid_df_cont.values.shape[0], valid_df_cont.values.shape[1])<(1- config.keep_prop)\n",
    "\n",
    "    np.random.seed(seed=19)\n",
    "    config.vaild_test_drop_mask = np.random.rand(valid_df_cate.values.shape[0], valid_df_cate.values.shape[1])>(1- config.keep_prop)\n",
    "    config.vaild_test_cont_mask = np.random.rand(valid_df_cont.values.shape[0], valid_df_cont.values.shape[1])<(1- config.keep_prop)\n",
    "\n",
    "    train_step = math.ceil(len(train_df)/ config.batch_size)\n",
    "    valid_step = math.ceil(len(valid_df)/ config.batch_size)\n",
    "    print(\"Data is Ready...\")\n",
    "\n",
    "    mdl = build_model(config)\n",
    "    print(\"Model {} is built...\".format(mdl_num))\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # run session\n",
    "    with tf.Session() as sess:\n",
    "        tf.set_random_seed(seed=1991)\n",
    "        np.random.seed(seed=1991)\n",
    "        sess.run(init)\n",
    "    #     saver.restore(sess, config.path_ckpt)\n",
    "        min_val_loss = 9999\n",
    "        print(\"Model {} is training\".format(mdl_num))\n",
    "        for epoch in range(1, config.epochs+1):\n",
    "            #train\n",
    "            trn_total_loss_ = run_session(sess, train_step, [train_df_cate, train_df_cont], config, mdl, mode=1)\n",
    "            \n",
    "            #valid\n",
    "            val_total_loss_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=2)\n",
    "            \n",
    "            if config.verbose:\n",
    "                print(\"Epoch : {}\".format(epoch), end='\\t')\n",
    "                print(\"Train_loss : {:.6f} / {:.6f} / {:.6f}\".format(trn_total_loss_[0], trn_total_loss_[1], trn_total_loss_[2]), end = '\\t')\n",
    "                print(\"Valid_loss : {:.6f} / {:.6f} / {:.6f}\".format(val_total_loss_[0], val_total_loss_[1], val_total_loss_[2]), end = '\\t')\n",
    "            \n",
    "            #monitor\n",
    "            if val_total_loss_[0] < min_val_loss:\n",
    "                saver.save(sess, config.path_ckpt)\n",
    "                min_val_loss = val_total_loss_[0]\n",
    "                if config.verbose:\n",
    "                    print(\"Saved\")\n",
    "            else:\n",
    "                if config.verbose:\n",
    "                    print(\"No Saved\")\n",
    "        print(\"Training Model {} of 3 is Completed...\".format(mdl_num))\n",
    "        \n",
    "print(\"Train is Ended, Do Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.cate_out_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(preds_cate_, preds_cont_):\n",
    "    #out\n",
    "    print(\"Exproting...\")\n",
    "    #cliping\n",
    "    preds_cont_[preds_cont_<0] = 0.0\n",
    "\n",
    "    # Categorical Vals Restore\n",
    "    pred_args = []\n",
    "    for p_ in preds_cate_:\n",
    "        start_idx = 0\n",
    "        pred_arg = []\n",
    "        for kl in config.cate_lens:\n",
    "            pred_arg.append(np.argmax(p_[start_idx: start_idx+kl]))\n",
    "            start_idx += kl\n",
    "        pred_args.append(pred_arg)\n",
    "    pred_args_np = np.array(pred_args)   \n",
    "\n",
    "\n",
    "    total_cell = ((config.vaild_test_drop_mask - 1) * -1)\n",
    "\n",
    "    pred_cells = (pred_args_np * total_cell)\n",
    "\n",
    "    true_cells = valid_df_cate.values\n",
    "     \n",
    "    cate_score = (pred_cells == true_cells).sum() / total_cell.sum()\n",
    "    nume_score = (np.exp(-np.square(preds_cont_ - valid_df_cont.values)) * config.vaild_test_cont_mask).sum() / config.vaild_test_cont_mask.sum()\n",
    "    print('categorical_score:', cate_score)\n",
    "    print('numeric_score:', nume_score)\n",
    "    print('total_score', cate_score + nume_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best1.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,3] rhs shape= [64,3]\n\t [[Node: save/Assign_77 = Assign[T=DT_FLOAT, _class=[\"loc:@fully_connected_4/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fully_connected_4/weights, save/RestoreV2/_155)]]\n\t [[Node: save/RestoreV2/_162 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_168_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:81)]]\n\nCaused by op 'save/Assign_77', defined at:\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-674261501ff3>\", line 59, in <module>\n    saver = tf.train.Saver(max_to_keep=5)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,3] rhs shape= [64,3]\n\t [[Node: save/Assign_77 = Assign[T=DT_FLOAT, _class=[\"loc:@fully_connected_4/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fully_connected_4/weights, save/RestoreV2/_155)]]\n\t [[Node: save/RestoreV2/_162 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_168_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:81)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [256,3] rhs shape= [64,3]\n\t [[Node: save/Assign_77 = Assign[T=DT_FLOAT, _class=[\"loc:@fully_connected_4/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fully_connected_4/weights, save/RestoreV2/_155)]]\n\t [[Node: save/RestoreV2/_162 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_168_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:81)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1724\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1725\u001b[1;33m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1726\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [256,3] rhs shape= [64,3]\n\t [[Node: save/Assign_77 = Assign[T=DT_FLOAT, _class=[\"loc:@fully_connected_4/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fully_connected_4/weights, save/RestoreV2/_155)]]\n\t [[Node: save/RestoreV2/_162 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_168_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:81)]]\n\nCaused by op 'save/Assign_77', defined at:\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-674261501ff3>\", line 59, in <module>\n    saver = tf.train.Saver(max_to_keep=5)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [256,3] rhs shape= [64,3]\n\t [[Node: save/Assign_77 = Assign[T=DT_FLOAT, _class=[\"loc:@fully_connected_4/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fully_connected_4/weights, save/RestoreV2/_155)]]\n\t [[Node: save/RestoreV2/_162 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_168_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:81)]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d366b416c7c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicting...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.\\\\ckpt\\\\best1.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpreds_cate_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_cont_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalid_df_cate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_df_cont\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1757\u001b[0m       \u001b[1;31m# We add a more reasonable error message here to help users (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m       raise _wrap_restore_error_with_msg(\n\u001b[1;32m-> 1759\u001b[1;33m           err, \"a mismatch between the current graph and the graph\")\n\u001b[0m\u001b[0;32m   1760\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m   def _restore_from_object_based_checkpoint(self, sess, save_path,\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,3] rhs shape= [64,3]\n\t [[Node: save/Assign_77 = Assign[T=DT_FLOAT, _class=[\"loc:@fully_connected_4/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fully_connected_4/weights, save/RestoreV2/_155)]]\n\t [[Node: save/RestoreV2/_162 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_168_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:81)]]\n\nCaused by op 'save/Assign_77', defined at:\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-674261501ff3>\", line 59, in <module>\n    saver = tf.train.Saver(max_to_keep=5)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1281, in __init__\n    self.build()\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1330, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 778, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(saveable_tensors, shapes))\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 112, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 216, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 63, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a mismatch between the current graph and the graph from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nAssign requires shapes of both tensors to match. lhs shape= [256,3] rhs shape= [64,3]\n\t [[Node: save/Assign_77 = Assign[T=DT_FLOAT, _class=[\"loc:@fully_connected_4/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fully_connected_4/weights, save/RestoreV2/_155)]]\n\t [[Node: save/RestoreV2/_162 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_168_save/RestoreV2\", _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](save/RestoreV2:81)]]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(\"Predicting...\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best1.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=3)\n",
    "\n",
    "    preds_cate_1 = np.concatenate(preds_cate_)\n",
    "    preds_cont_1 = np.concatenate(preds_cont_)\n",
    "    eval_score(preds_cate_1, preds_cont_1)\n",
    "\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best2.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=3)\n",
    "\n",
    "    preds_cate_2 = np.concatenate(preds_cate_)\n",
    "    preds_cont_2 = np.concatenate(preds_cont_)\n",
    "    eval_score(preds_cate_2, preds_cont_2)\n",
    "\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best3.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=3)\n",
    "\n",
    "    preds_cate_3 = np.concatenate(preds_cate_)\n",
    "    preds_cont_3 = np.concatenate(preds_cont_)\n",
    "    eval_score(preds_cate_3, preds_cont_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
