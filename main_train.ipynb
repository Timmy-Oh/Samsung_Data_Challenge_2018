{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timmy-yonsei\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is Ready...\n",
      "Model 1 is built...\n",
      "Model 1 is training\n",
      "Epoch : 1\tTrain_loss : 23.640390 / 21.692763 / 0.973814\tValid_loss : 17.843201 / 16.809255 / 0.516973\tSaved\n",
      "Epoch : 2\tTrain_loss : 15.038313 / 14.129243 / 0.454535\tValid_loss : 12.243634 / 11.492975 / 0.375330\tSaved\n",
      "Epoch : 3\tTrain_loss : 10.414303 / 9.812088 / 0.301108\tValid_loss : 8.911087 / 8.341046 / 0.285021\tSaved\n",
      "Epoch : 4\tTrain_loss : 7.828258 / 7.358059 / 0.235099\tValid_loss : 7.076513 / 6.593978 / 0.241267\tSaved\n",
      "Epoch : 5\tTrain_loss : 6.399501 / 5.980609 / 0.209446\tValid_loss : 6.020309 / 5.610040 / 0.205134\tSaved\n",
      "Epoch : 6\tTrain_loss : 5.679853 / 5.187026 / 0.246414\tValid_loss : 5.411513 / 5.014804 / 0.198355\tSaved\n",
      "Epoch : 7\tTrain_loss : 5.046168 / 4.698516 / 0.173826\tValid_loss : 5.045877 / 4.674028 / 0.185924\tSaved\n",
      "Epoch : 8\tTrain_loss : 4.694209 / 4.403048 / 0.145580\tValid_loss : 4.807809 / 4.443518 / 0.182145\tSaved\n",
      "Epoch : 9\tTrain_loss : 4.517829 / 4.214944 / 0.151442\tValid_loss : 4.676309 / 4.312336 / 0.181986\tSaved\n",
      "Epoch : 10\tTrain_loss : 4.369347 / 4.099456 / 0.134946\tValid_loss : 4.512438 / 4.188401 / 0.162018\tSaved\n",
      "Epoch : 11\tTrain_loss : 4.245063 / 3.962202 / 0.141431\tValid_loss : 4.443465 / 4.132249 / 0.155608\tSaved\n",
      "Epoch : 12\tTrain_loss : 4.203508 / 3.925232 / 0.139138\tValid_loss : 4.380931 / 4.066683 / 0.157124\tSaved\n",
      "Epoch : 13\tTrain_loss : 4.263677 / 3.827202 / 0.218237\tValid_loss : 4.338238 / 4.034278 / 0.151980\tSaved\n",
      "Epoch : 14\tTrain_loss : 4.144503 / 3.828655 / 0.157924\tValid_loss : 4.323593 / 4.005210 / 0.159191\tSaved\n",
      "Epoch : 15\tTrain_loss : 4.367681 / 3.787776 / 0.289952\tValid_loss : 4.293995 / 3.985162 / 0.154416\tSaved\n",
      "Epoch : 16\tTrain_loss : 4.187584 / 3.774926 / 0.206329\tValid_loss : 4.277512 / 3.964673 / 0.156419\tSaved\n",
      "Epoch : 17\tTrain_loss : 4.210409 / 3.747526 / 0.231441\tValid_loss : 4.269937 / 3.952828 / 0.158554\tSaved\n",
      "Epoch : 18\tTrain_loss : 4.040252 / 3.712978 / 0.163637\tValid_loss : 4.251467 / 3.935043 / 0.158212\tSaved\n",
      "Epoch : 19\tTrain_loss : 3.920052 / 3.686854 / 0.116599\tValid_loss : 4.231374 / 3.935773 / 0.147801\tSaved\n",
      "Epoch : 20\tTrain_loss : 4.113965 / 3.723728 / 0.195118\tValid_loss : 4.197804 / 3.895672 / 0.151066\tSaved\n",
      "Epoch : 21\tTrain_loss : 3.981017 / 3.684933 / 0.148042\tValid_loss : 4.205787 / 3.899504 / 0.153141\tNo Saved\n",
      "Epoch : 22\tTrain_loss : 3.883376 / 3.639096 / 0.122140\tValid_loss : 4.175204 / 3.875932 / 0.149636\tSaved\n",
      "Epoch : 23\tTrain_loss : 3.962799 / 3.699143 / 0.131828\tValid_loss : 4.192166 / 3.886422 / 0.152872\tNo Saved\n",
      "Epoch : 24\tTrain_loss : 4.004643 / 3.628060 / 0.188292\tValid_loss : 4.169210 / 3.876958 / 0.146126\tSaved\n",
      "Epoch : 25\tTrain_loss : 3.960323 / 3.679597 / 0.140363\tValid_loss : 4.182674 / 3.877360 / 0.152657\tNo Saved\n",
      "Epoch : 26\tTrain_loss : 3.938825 / 3.649924 / 0.144450\tValid_loss : 4.167992 / 3.875704 / 0.146144\tSaved\n",
      "Epoch : 27\tTrain_loss : 3.874763 / 3.615241 / 0.129761\tValid_loss : 4.116897 / 3.850856 / 0.133020\tSaved\n",
      "Epoch : 28\tTrain_loss : 3.895941 / 3.653655 / 0.121143\tValid_loss : 4.118996 / 3.848550 / 0.135223\tNo Saved\n",
      "Epoch : 29\tTrain_loss : 4.307127 / 3.647856 / 0.329635\tValid_loss : 4.140850 / 3.861136 / 0.139857\tNo Saved\n",
      "Epoch : 30\tTrain_loss : 3.842140 / 3.620246 / 0.110947\tValid_loss : 4.135030 / 3.865620 / 0.134705\tNo Saved\n",
      "Epoch : 31\tTrain_loss : 3.864088 / 3.609291 / 0.127398\tValid_loss : 4.109659 / 3.848587 / 0.130536\tSaved\n",
      "Epoch : 32\tTrain_loss : 3.913255 / 3.645261 / 0.133997\tValid_loss : 4.075633 / 3.846212 / 0.114710\tSaved\n",
      "Epoch : 33\tTrain_loss : 3.921295 / 3.609177 / 0.156059\tValid_loss : 4.117392 / 3.842675 / 0.137358\tNo Saved\n",
      "Epoch : 34\tTrain_loss : 3.840090 / 3.585005 / 0.127542\tValid_loss : 4.133255 / 3.865525 / 0.133865\tNo Saved\n",
      "Epoch : 35\tTrain_loss : 3.838987 / 3.623451 / 0.107768\tValid_loss : 4.093135 / 3.842715 / 0.125210\tNo Saved\n",
      "Epoch : 36\tTrain_loss : 3.873384 / 3.582556 / 0.145414\tValid_loss : 4.122166 / 3.852086 / 0.135040\tNo Saved\n",
      "Epoch : 37\tTrain_loss : 3.823452 / 3.602879 / 0.110287\tValid_loss : 4.078862 / 3.823449 / 0.127707\tNo Saved\n",
      "Epoch : 38\tTrain_loss : 4.145901 / 3.556294 / 0.294804\tValid_loss : 4.086917 / 3.848947 / 0.118985\tNo Saved\n",
      "Epoch : 39\tTrain_loss : 3.734918 / 3.581780 / 0.076569\tValid_loss : 4.059628 / 3.829261 / 0.115184\tSaved\n",
      "Epoch : 40\tTrain_loss : 3.744706 / 3.562437 / 0.091135\tValid_loss : 4.100055 / 3.857941 / 0.121057\tNo Saved\n",
      "Epoch : 41\tTrain_loss : 3.881986 / 3.575461 / 0.153262\tValid_loss : 4.065001 / 3.823033 / 0.120984\tNo Saved\n",
      "Epoch : 42\tTrain_loss : 3.855198 / 3.577318 / 0.138940\tValid_loss : 4.087396 / 3.844863 / 0.121267\tNo Saved\n",
      "Epoch : 43\tTrain_loss : 3.856412 / 3.549717 / 0.153348\tValid_loss : 4.068934 / 3.840216 / 0.114359\tNo Saved\n",
      "Epoch : 44\tTrain_loss : 3.994552 / 3.556493 / 0.219029\tValid_loss : 4.097975 / 3.824471 / 0.136752\tNo Saved\n",
      "Epoch : 45\tTrain_loss : 3.888964 / 3.589486 / 0.149739\tValid_loss : 4.110757 / 3.833161 / 0.138798\tNo Saved\n",
      "Epoch : 46\tTrain_loss : 3.887608 / 3.575101 / 0.156253\tValid_loss : 4.084069 / 3.826139 / 0.128965\tNo Saved\n",
      "Epoch : 47\tTrain_loss : 3.781139 / 3.571626 / 0.104756\tValid_loss : 4.095211 / 3.831069 / 0.132071\tNo Saved\n",
      "Epoch : 48\tTrain_loss : 3.834302 / 3.565176 / 0.134563\tValid_loss : 4.070758 / 3.824105 / 0.123326\tNo Saved\n",
      "Epoch : 49\tTrain_loss : 3.881093 / 3.570846 / 0.155123\tValid_loss : 4.067709 / 3.818148 / 0.124781\tNo Saved\n",
      "Epoch : 50\tTrain_loss : 3.914490 / 3.540915 / 0.186788\tValid_loss : 4.082308 / 3.830680 / 0.125814\tNo Saved\n",
      "Epoch : 51\tTrain_loss : 3.782686 / 3.538182 / 0.122252\tValid_loss : 4.075712 / 3.822755 / 0.126478\tNo Saved\n",
      "Epoch : 52\tTrain_loss : 3.775445 / 3.560552 / 0.107446\tValid_loss : 4.056908 / 3.822043 / 0.117432\tSaved\n",
      "Epoch : 53\tTrain_loss : 3.765357 / 3.552597 / 0.106380\tValid_loss : 4.066234 / 3.817745 / 0.124245\tNo Saved\n",
      "Epoch : 54\tTrain_loss : 3.804358 / 3.551760 / 0.126299\tValid_loss : 4.067990 / 3.815894 / 0.126048\tNo Saved\n",
      "Epoch : 55\tTrain_loss : 3.706472 / 3.533820 / 0.086326\tValid_loss : 4.052816 / 3.824609 / 0.114103\tSaved\n",
      "Epoch : 56\tTrain_loss : 3.781333 / 3.529693 / 0.125820\tValid_loss : 4.047121 / 3.809173 / 0.118974\tSaved\n",
      "Epoch : 57\tTrain_loss : 3.929715 / 3.530168 / 0.199774\tValid_loss : 4.041038 / 3.814305 / 0.113366\tSaved\n",
      "Epoch : 58\tTrain_loss : 3.748119 / 3.526018 / 0.111051\tValid_loss : 4.150649 / 3.811251 / 0.169699\tNo Saved\n",
      "Epoch : 59\tTrain_loss : 3.783542 / 3.537996 / 0.122773\tValid_loss : 4.087473 / 3.825316 / 0.131078\tNo Saved\n",
      "Epoch : 60\tTrain_loss : 3.697844 / 3.500791 / 0.098527\tValid_loss : 4.044079 / 3.812709 / 0.115685\tNo Saved\n",
      "Epoch : 61\tTrain_loss : 3.778391 / 3.522749 / 0.127821\tValid_loss : 4.055929 / 3.822027 / 0.116951\tNo Saved\n",
      "Epoch : 62\tTrain_loss : 3.842063 / 3.508515 / 0.166774\tValid_loss : 4.061946 / 3.820431 / 0.120757\tNo Saved\n",
      "Epoch : 63\tTrain_loss : 3.762008 / 3.504856 / 0.128576\tValid_loss : 4.095782 / 3.810453 / 0.142665\tNo Saved\n",
      "Epoch : 64\tTrain_loss : 3.956277 / 3.552897 / 0.201690\tValid_loss : 4.084996 / 3.811753 / 0.136621\tNo Saved\n",
      "Epoch : 65\tTrain_loss : 3.693370 / 3.497439 / 0.097965\tValid_loss : 4.084395 / 3.829531 / 0.127432\tNo Saved\n",
      "Epoch : 66\tTrain_loss : 3.749090 / 3.525257 / 0.111917\tValid_loss : 4.091245 / 3.817014 / 0.137115\tNo Saved\n",
      "Epoch : 67\tTrain_loss : 3.678849 / 3.513037 / 0.082906\tValid_loss : 4.072178 / 3.820167 / 0.126005\tNo Saved\n",
      "Epoch : 68\tTrain_loss : 3.734195 / 3.497003 / 0.118596\tValid_loss : 4.078695 / 3.813723 / 0.132486\tNo Saved\n",
      "Epoch : 69\tTrain_loss : 3.654795 / 3.487232 / 0.083781\tValid_loss : 4.071986 / 3.822983 / 0.124502\tNo Saved\n",
      "Epoch : 70\tTrain_loss : 3.716453 / 3.507149 / 0.104652\tValid_loss : 4.059007 / 3.817270 / 0.120869\tNo Saved\n",
      "Epoch : 71\tTrain_loss : 3.835997 / 3.506432 / 0.164783\tValid_loss : 4.077205 / 3.845284 / 0.115960\tNo Saved\n",
      "Epoch : 72\tTrain_loss : 3.791347 / 3.500394 / 0.145477\tValid_loss : 4.052124 / 3.814159 / 0.118982\tNo Saved\n",
      "Epoch : 73\tTrain_loss : 3.912251 / 3.526234 / 0.193009\tValid_loss : 4.079856 / 3.812165 / 0.133845\tNo Saved\n",
      "Epoch : 74\tTrain_loss : 3.688062 / 3.475914 / 0.106074\tValid_loss : 4.052160 / 3.820921 / 0.115620\tNo Saved\n",
      "Epoch : 75\tTrain_loss : 3.681632 / 3.517999 / 0.081816\tValid_loss : 4.051954 / 3.823804 / 0.114075\tNo Saved\n",
      "Epoch : 76\tTrain_loss : 3.811534 / 3.515655 / 0.147939\tValid_loss : 4.061814 / 3.826992 / 0.117411\tNo Saved\n",
      "Epoch : 77\tTrain_loss : 3.679543 / 3.497429 / 0.091057\tValid_loss : 4.036613 / 3.816194 / 0.110210\tSaved\n",
      "Epoch : 78\tTrain_loss : 3.634042 / 3.468545 / 0.082749\tValid_loss : 4.032886 / 3.806408 / 0.113239\tSaved\n",
      "Epoch : 79\tTrain_loss : 3.927209 / 3.506590 / 0.210309\tValid_loss : 4.053260 / 3.806849 / 0.123205\tNo Saved\n",
      "Epoch : 80\tTrain_loss : 4.106154 / 3.474181 / 0.315987\tValid_loss : 4.045721 / 3.807780 / 0.118970\tNo Saved\n",
      "Epoch : 81\tTrain_loss : 3.673069 / 3.466393 / 0.103338\tValid_loss : 4.031620 / 3.811467 / 0.110076\tSaved\n",
      "Epoch : 82\tTrain_loss : 3.826288 / 3.468121 / 0.179083\tValid_loss : 4.035201 / 3.809847 / 0.112677\tNo Saved\n",
      "Epoch : 83\tTrain_loss : 3.743165 / 3.456083 / 0.143541\tValid_loss : 4.050364 / 3.801738 / 0.124313\tNo Saved\n",
      "Epoch : 84\tTrain_loss : 3.865595 / 3.438816 / 0.213389\tValid_loss : 4.038588 / 3.803578 / 0.117505\tNo Saved\n",
      "Epoch : 85\tTrain_loss : 3.632063 / 3.448648 / 0.091707\tValid_loss : 4.099473 / 3.813634 / 0.142920\tNo Saved\n",
      "Epoch : 86\tTrain_loss : 3.818455 / 3.511313 / 0.153571\tValid_loss : 4.053650 / 3.821947 / 0.115852\tNo Saved\n",
      "Epoch : 87\tTrain_loss : 3.776924 / 3.523157 / 0.126884\tValid_loss : 4.041661 / 3.814299 / 0.113681\tNo Saved\n",
      "Epoch : 88\tTrain_loss : 3.592756 / 3.464236 / 0.064260\tValid_loss : 4.032119 / 3.812216 / 0.109952\tNo Saved\n",
      "Epoch : 89\tTrain_loss : 3.605686 / 3.473092 / 0.066297\tValid_loss : 4.037336 / 3.818419 / 0.109458\tNo Saved\n",
      "Epoch : 90\tTrain_loss : 3.626410 / 3.455364 / 0.085523\tValid_loss : 4.010531 / 3.811620 / 0.099456\tSaved\n",
      "Epoch : 91\tTrain_loss : 3.628548 / 3.447516 / 0.090516\tValid_loss : 4.011172 / 3.801487 / 0.104842\tNo Saved\n",
      "Epoch : 92\tTrain_loss : 3.918871 / 3.456340 / 0.231265\tValid_loss : 4.039123 / 3.808768 / 0.115178\tNo Saved\n",
      "Epoch : 93\tTrain_loss : 3.661304 / 3.471946 / 0.094679\tValid_loss : 4.050102 / 3.807251 / 0.121426\tNo Saved\n",
      "Epoch : 94\tTrain_loss : 3.663988 / 3.460469 / 0.101760\tValid_loss : 4.026673 / 3.800697 / 0.112988\tNo Saved\n",
      "Epoch : 95\tTrain_loss : 3.797917 / 3.508182 / 0.144868\tValid_loss : 4.043588 / 3.806813 / 0.118387\tNo Saved\n",
      "Epoch : 96\tTrain_loss : 3.689400 / 3.464646 / 0.112377\tValid_loss : 4.047288 / 3.820533 / 0.113378\tNo Saved\n",
      "Epoch : 97\tTrain_loss : 3.663180 / 3.465794 / 0.098693\tValid_loss : 4.034839 / 3.817837 / 0.108501\tNo Saved\n",
      "Epoch : 98\tTrain_loss : 3.706989 / 3.475581 / 0.115704\tValid_loss : 4.023908 / 3.807936 / 0.107986\tNo Saved\n",
      "Epoch : 99\tTrain_loss : 3.825110 / 3.465671 / 0.179720\tValid_loss : 4.056122 / 3.832914 / 0.111604\tNo Saved\n",
      "Epoch : 100\tTrain_loss : 3.759502 / 3.488151 / 0.135675\tValid_loss : 4.078593 / 3.829586 / 0.124503\tNo Saved\n",
      "Epoch : 101\tTrain_loss : 3.820457 / 3.473629 / 0.173414\tValid_loss : 4.056812 / 3.828915 / 0.113949\tNo Saved\n",
      "Epoch : 102\tTrain_loss : 3.690192 / 3.438570 / 0.125811\tValid_loss : 4.041704 / 3.816023 / 0.112840\tNo Saved\n",
      "Epoch : 103\tTrain_loss : 3.685883 / 3.445333 / 0.120275\tValid_loss : 4.020866 / 3.801780 / 0.109543\tNo Saved\n",
      "Epoch : 104\tTrain_loss : 3.575822 / 3.428007 / 0.073908\tValid_loss : 4.019482 / 3.814335 / 0.102573\tNo Saved\n",
      "Epoch : 105\tTrain_loss : 3.758512 / 3.440116 / 0.159198\tValid_loss : 4.038254 / 3.815742 / 0.111256\tNo Saved\n",
      "Epoch : 106\tTrain_loss : 3.702375 / 3.440720 / 0.130828\tValid_loss : 4.063920 / 3.832049 / 0.115935\tNo Saved\n",
      "Epoch : 107\tTrain_loss : 3.646269 / 3.439783 / 0.103243\tValid_loss : 4.031758 / 3.810503 / 0.110627\tNo Saved\n",
      "Epoch : 108\tTrain_loss : 3.611071 / 3.439822 / 0.085624\tValid_loss : 4.045102 / 3.827368 / 0.108867\tNo Saved\n",
      "Epoch : 109\tTrain_loss : 3.945463 / 3.442397 / 0.251533\tValid_loss : 4.057390 / 3.824253 / 0.116568\tNo Saved\n",
      "Epoch : 110\tTrain_loss : 3.683681 / 3.426938 / 0.128371\tValid_loss : 4.027158 / 3.800180 / 0.113489\tNo Saved\n",
      "Epoch : 111\tTrain_loss : 3.733678 / 3.450055 / 0.141811\tValid_loss : 4.034306 / 3.808169 / 0.113068\tNo Saved\n",
      "Epoch : 112\tTrain_loss : 3.711683 / 3.424224 / 0.143729\tValid_loss : 4.026628 / 3.809522 / 0.108553\tNo Saved\n",
      "Epoch : 113\tTrain_loss : 3.690176 / 3.414873 / 0.137652\tValid_loss : 4.036221 / 3.824390 / 0.105916\tNo Saved\n",
      "Epoch : 114\tTrain_loss : 3.577697 / 3.420129 / 0.078784\tValid_loss : 4.053006 / 3.818538 / 0.117234\tNo Saved\n",
      "Epoch : 115\tTrain_loss : 3.645787 / 3.430875 / 0.107456\tValid_loss : 4.063714 / 3.816492 / 0.123611\tNo Saved\n",
      "Epoch : 116\tTrain_loss : 3.553556 / 3.393602 / 0.079977\tValid_loss : 4.033995 / 3.813619 / 0.110188\tNo Saved\n",
      "Epoch : 117\tTrain_loss : 3.615857 / 3.417549 / 0.099154\tValid_loss : 4.034753 / 3.827114 / 0.103819\tNo Saved\n",
      "Epoch : 118\tTrain_loss : 3.613922 / 3.458753 / 0.077584\tValid_loss : 4.028754 / 3.823001 / 0.102877\tNo Saved\n",
      "Epoch : 119\tTrain_loss : 3.717591 / 3.435687 / 0.140952\tValid_loss : 4.051419 / 3.837512 / 0.106954\tNo Saved\n",
      "Epoch : 120\tTrain_loss : 3.714372 / 3.438732 / 0.137820\tValid_loss : 4.058632 / 3.836546 / 0.111043\tNo Saved\n",
      "Epoch : 121\tTrain_loss : 3.542269 / 3.415394 / 0.063437\tValid_loss : 4.050717 / 3.836325 / 0.107196\tNo Saved\n",
      "Epoch : 122\tTrain_loss : 3.561209 / 3.418038 / 0.071585\tValid_loss : 4.043233 / 3.835819 / 0.103707\tNo Saved\n",
      "Epoch : 123\tTrain_loss : 3.627172 / 3.436441 / 0.095366\tValid_loss : 4.041225 / 3.835023 / 0.103101\tNo Saved\n",
      "Epoch : 124\tTrain_loss : 3.643986 / 3.457309 / 0.093339\tValid_loss : 4.020825 / 3.826461 / 0.097182\tNo Saved\n",
      "Epoch : 125\tTrain_loss : 3.647293 / 3.446402 / 0.100445\tValid_loss : 4.035575 / 3.830633 / 0.102471\tNo Saved\n",
      "Epoch : 126\tTrain_loss : 3.683434 / 3.463936 / 0.109749\tValid_loss : 4.015418 / 3.817698 / 0.098860\tNo Saved\n",
      "Epoch : 127\tTrain_loss : 3.611011 / 3.468812 / 0.071099\tValid_loss : 4.015499 / 3.809282 / 0.103109\tNo Saved\n",
      "Epoch : 128\tTrain_loss : 3.553697 / 3.387667 / 0.083015\tValid_loss : 4.027694 / 3.816600 / 0.105547\tNo Saved\n",
      "Epoch : 129\tTrain_loss : 3.616759 / 3.419013 / 0.098873\tValid_loss : 4.031040 / 3.820195 / 0.105423\tNo Saved\n",
      "Epoch : 130\tTrain_loss : 3.826981 / 3.463341 / 0.181820\tValid_loss : 4.037391 / 3.822902 / 0.107244\tNo Saved\n",
      "Epoch : 131\tTrain_loss : 3.621038 / 3.442858 / 0.089090\tValid_loss : 4.082607 / 3.825691 / 0.128458\tNo Saved\n",
      "Epoch : 132\tTrain_loss : 3.597026 / 3.457372 / 0.069827\tValid_loss : 4.044014 / 3.822881 / 0.110566\tNo Saved\n",
      "Epoch : 133\tTrain_loss : 3.545818 / 3.397195 / 0.074312\tValid_loss : 4.023498 / 3.817801 / 0.102849\tNo Saved\n",
      "Epoch : 134\tTrain_loss : 3.745231 / 3.448954 / 0.148139\tValid_loss : 4.045006 / 3.836098 / 0.104454\tNo Saved\n",
      "Epoch : 135\tTrain_loss : 3.595924 / 3.435327 / 0.080298\tValid_loss : 4.049277 / 3.828507 / 0.110385\tNo Saved\n",
      "Epoch : 136\tTrain_loss : 3.620476 / 3.434193 / 0.093142\tValid_loss : 4.038257 / 3.828959 / 0.104649\tNo Saved\n",
      "Epoch : 137\tTrain_loss : 3.585329 / 3.439821 / 0.072754\tValid_loss : 4.024219 / 3.839373 / 0.092423\tNo Saved\n",
      "Epoch : 138\tTrain_loss : 3.570680 / 3.412412 / 0.079134\tValid_loss : 4.039515 / 3.832557 / 0.103479\tNo Saved\n",
      "Epoch : 139\tTrain_loss : 3.713904 / 3.436378 / 0.138763\tValid_loss : 4.048084 / 3.822799 / 0.112643\tNo Saved\n",
      "Epoch : 140\tTrain_loss : 3.737475 / 3.448653 / 0.144411\tValid_loss : 4.055616 / 3.830208 / 0.112704\tNo Saved\n",
      "Epoch : 141\tTrain_loss : 3.639730 / 3.410406 / 0.114662\tValid_loss : 4.036080 / 3.821208 / 0.107436\tNo Saved\n",
      "Epoch : 142\tTrain_loss : 3.710675 / 3.411190 / 0.149742\tValid_loss : 4.044248 / 3.833724 / 0.105262\tNo Saved\n",
      "Epoch : 143\tTrain_loss : 3.682699 / 3.387187 / 0.147756\tValid_loss : 4.022425 / 3.827807 / 0.097309\tNo Saved\n",
      "Epoch : 144\tTrain_loss : 3.771234 / 3.431808 / 0.169713\tValid_loss : 4.069826 / 3.844004 / 0.112911\tNo Saved\n",
      "Epoch : 145\tTrain_loss : 3.633464 / 3.438144 / 0.097660\tValid_loss : 4.099704 / 3.839650 / 0.130027\tNo Saved\n",
      "Epoch : 146\tTrain_loss : 3.532797 / 3.394429 / 0.069184\tValid_loss : 4.093549 / 3.854891 / 0.119329\tNo Saved\n",
      "Epoch : 147\tTrain_loss : 3.657438 / 3.401138 / 0.128150\tValid_loss : 4.047745 / 3.835442 / 0.106151\tNo Saved\n",
      "Epoch : 148\tTrain_loss : 3.519548 / 3.361757 / 0.078896\tValid_loss : 4.055010 / 3.831697 / 0.111656\tNo Saved\n",
      "Epoch : 149\tTrain_loss : 3.604637 / 3.421374 / 0.091632\tValid_loss : 4.036046 / 3.829549 / 0.103248\tNo Saved\n",
      "Epoch : 150\tTrain_loss : 3.566009 / 3.405772 / 0.080119\tValid_loss : 4.047717 / 3.835467 / 0.106125\tNo Saved\n",
      "Epoch : 151\tTrain_loss : 3.572595 / 3.384944 / 0.093825\tValid_loss : 4.030927 / 3.841966 / 0.094480\tNo Saved\n",
      "Epoch : 152\tTrain_loss : 3.742544 / 3.398000 / 0.172272\tValid_loss : 4.044471 / 3.849371 / 0.097550\tNo Saved\n",
      "Epoch : 153\tTrain_loss : 3.569083 / 3.381027 / 0.094028\tValid_loss : 4.026415 / 3.835735 / 0.095340\tNo Saved\n",
      "Epoch : 154\tTrain_loss : 3.605808 / 3.392098 / 0.106855\tValid_loss : 4.046308 / 3.832650 / 0.106829\tNo Saved\n",
      "Epoch : 155\tTrain_loss : 3.657730 / 3.388612 / 0.134559\tValid_loss : 4.041213 / 3.828085 / 0.106564\tNo Saved\n",
      "Epoch : 156\tTrain_loss : 3.649952 / 3.409145 / 0.120404\tValid_loss : 4.071355 / 3.830721 / 0.120317\tNo Saved\n",
      "Epoch : 157\tTrain_loss : 3.608269 / 3.417974 / 0.095147\tValid_loss : 4.043930 / 3.829719 / 0.107106\tNo Saved\n",
      "Epoch : 158\tTrain_loss : 3.680415 / 3.397360 / 0.141527\tValid_loss : 4.053066 / 3.829035 / 0.112015\tNo Saved\n",
      "Epoch : 159\tTrain_loss : 3.628801 / 3.411859 / 0.108471\tValid_loss : 4.063297 / 3.825205 / 0.119046\tNo Saved\n",
      "Epoch : 160\tTrain_loss : 3.526329 / 3.384276 / 0.071027\tValid_loss : 4.054378 / 3.828717 / 0.112830\tNo Saved\n",
      "Epoch : 161\tTrain_loss : 3.642338 / 3.406659 / 0.117840\tValid_loss : 4.046000 / 3.832673 / 0.106664\tNo Saved\n",
      "Epoch : 162\tTrain_loss : 3.553979 / 3.367698 / 0.093141\tValid_loss : 4.044674 / 3.840535 / 0.102069\tNo Saved\n",
      "Epoch : 163\tTrain_loss : 3.567090 / 3.397380 / 0.084855\tValid_loss : 4.076204 / 3.856499 / 0.109853\tNo Saved\n",
      "Epoch : 164\tTrain_loss : 3.546844 / 3.375291 / 0.085777\tValid_loss : 4.041285 / 3.830928 / 0.105178\tNo Saved\n",
      "Epoch : 165\tTrain_loss : 3.616748 / 3.329083 / 0.143833\tValid_loss : 4.039410 / 3.834238 / 0.102586\tNo Saved\n",
      "Epoch : 166\tTrain_loss : 3.628036 / 3.357829 / 0.135103\tValid_loss : 4.097968 / 3.853129 / 0.122420\tNo Saved\n",
      "Epoch : 167\tTrain_loss : 3.555630 / 3.388726 / 0.083452\tValid_loss : 4.051780 / 3.836542 / 0.107619\tNo Saved\n",
      "Epoch : 168\tTrain_loss : 3.642131 / 3.406599 / 0.117766\tValid_loss : 4.049356 / 3.843888 / 0.102734\tNo Saved\n",
      "Epoch : 169\tTrain_loss : 3.598580 / 3.399163 / 0.099709\tValid_loss : 4.059545 / 3.855843 / 0.101851\tNo Saved\n",
      "Epoch : 170\tTrain_loss : 3.538165 / 3.362323 / 0.087921\tValid_loss : 4.057461 / 3.852675 / 0.102393\tNo Saved\n",
      "Epoch : 171\tTrain_loss : 3.556248 / 3.414554 / 0.070847\tValid_loss : 4.041173 / 3.845069 / 0.098052\tNo Saved\n",
      "Epoch : 172\tTrain_loss : 3.948242 / 3.412296 / 0.267973\tValid_loss : 4.099024 / 3.835384 / 0.131820\tNo Saved\n",
      "Epoch : 173\tTrain_loss : 3.657245 / 3.360979 / 0.148133\tValid_loss : 4.045673 / 3.836275 / 0.104699\tNo Saved\n",
      "Epoch : 174\tTrain_loss : 3.534370 / 3.395194 / 0.069588\tValid_loss : 4.039200 / 3.837770 / 0.100715\tNo Saved\n",
      "Epoch : 175\tTrain_loss : 3.493767 / 3.361487 / 0.066140\tValid_loss : 4.064335 / 3.846156 / 0.109089\tNo Saved\n",
      "Epoch : 176\tTrain_loss : 3.562002 / 3.370553 / 0.095725\tValid_loss : 4.078817 / 3.841402 / 0.118707\tNo Saved\n",
      "Epoch : 177\tTrain_loss : 3.543818 / 3.410829 / 0.066495\tValid_loss : 4.086519 / 3.849621 / 0.118449\tNo Saved\n",
      "Epoch : 178\tTrain_loss : 3.534375 / 3.389055 / 0.072660\tValid_loss : 4.091542 / 3.856005 / 0.117768\tNo Saved\n",
      "Epoch : 179\tTrain_loss : 3.537735 / 3.380562 / 0.078587\tValid_loss : 4.056136 / 3.851997 / 0.102070\tNo Saved\n",
      "Epoch : 180\tTrain_loss : 3.499338 / 3.365340 / 0.066999\tValid_loss : 4.067534 / 3.864349 / 0.101592\tNo Saved\n",
      "Epoch : 181\tTrain_loss : 3.543110 / 3.360027 / 0.091542\tValid_loss : 4.055734 / 3.852113 / 0.101810\tNo Saved\n",
      "Epoch : 182\tTrain_loss : 3.616525 / 3.374581 / 0.120972\tValid_loss : 4.089913 / 3.883254 / 0.103329\tNo Saved\n",
      "Epoch : 183\tTrain_loss : 3.507105 / 3.347452 / 0.079827\tValid_loss : 4.044046 / 3.854150 / 0.094948\tNo Saved\n",
      "Epoch : 184\tTrain_loss : 3.582288 / 3.375578 / 0.103355\tValid_loss : 4.061198 / 3.857380 / 0.101909\tNo Saved\n",
      "Epoch : 185\tTrain_loss : 3.594952 / 3.334380 / 0.130286\tValid_loss : 4.054347 / 3.852332 / 0.101007\tNo Saved\n",
      "Epoch : 186\tTrain_loss : 3.541599 / 3.363859 / 0.088870\tValid_loss : 4.075684 / 3.872619 / 0.101533\tNo Saved\n",
      "Epoch : 187\tTrain_loss : 3.471892 / 3.334653 / 0.068619\tValid_loss : 4.101097 / 3.861245 / 0.119926\tNo Saved\n",
      "Epoch : 188\tTrain_loss : 3.595841 / 3.392638 / 0.101602\tValid_loss : 4.079532 / 3.865630 / 0.106951\tNo Saved\n",
      "Epoch : 189\tTrain_loss : 3.574907 / 3.383268 / 0.095819\tValid_loss : 4.078292 / 3.862819 / 0.107736\tNo Saved\n",
      "Epoch : 190\tTrain_loss : 3.530224 / 3.363770 / 0.083227\tValid_loss : 4.066481 / 3.849766 / 0.108357\tNo Saved\n",
      "Epoch : 191\tTrain_loss : 3.556180 / 3.374438 / 0.090871\tValid_loss : 4.048247 / 3.858908 / 0.094670\tNo Saved\n",
      "Epoch : 192\tTrain_loss : 3.513147 / 3.340836 / 0.086155\tValid_loss : 4.081315 / 3.859031 / 0.111142\tNo Saved\n",
      "Epoch : 193\tTrain_loss : 3.587029 / 3.400635 / 0.093197\tValid_loss : 4.109791 / 3.857673 / 0.126059\tNo Saved\n",
      "Epoch : 194\tTrain_loss : 3.510194 / 3.340995 / 0.084600\tValid_loss : 4.100137 / 3.857683 / 0.121227\tNo Saved\n",
      "Epoch : 195\tTrain_loss : 3.511789 / 3.341030 / 0.085380\tValid_loss : 4.086227 / 3.868379 / 0.108924\tNo Saved\n",
      "Epoch : 196\tTrain_loss : 3.796484 / 3.367818 / 0.214333\tValid_loss : 4.146659 / 3.868642 / 0.139008\tNo Saved\n",
      "Epoch : 197\tTrain_loss : 3.603658 / 3.342793 / 0.130432\tValid_loss : 4.169257 / 3.858196 / 0.155531\tNo Saved\n",
      "Epoch : 198\tTrain_loss : 3.499311 / 3.332143 / 0.083584\tValid_loss : 4.090828 / 3.851510 / 0.119659\tNo Saved\n",
      "Epoch : 199\tTrain_loss : 3.665907 / 3.405948 / 0.129980\tValid_loss : 4.144753 / 3.865159 / 0.139797\tNo Saved\n",
      "Epoch : 200\tTrain_loss : 3.557657 / 3.371053 / 0.093302\tValid_loss : 4.275472 / 3.875250 / 0.200111\tNo Saved\n",
      "Training Model 1 of 3 is Completed...\n",
      "Data is Ready...\n",
      "Model 2 is built...\n",
      "Model 2 is training\n",
      "Epoch : 1\tTrain_loss : 23.034731 / 20.901998 / 1.066367\tValid_loss : 17.449714 / 16.451607 / 0.499054\tSaved\n",
      "Epoch : 2\tTrain_loss : 14.579883 / 13.692489 / 0.443697\tValid_loss : 12.030555 / 11.316780 / 0.356888\tSaved\n",
      "Epoch : 3\tTrain_loss : 10.419000 / 9.605914 / 0.406543\tValid_loss : 8.827664 / 8.295663 / 0.266000\tSaved\n",
      "Epoch : 4\tTrain_loss : 7.736990 / 7.269923 / 0.233534\tValid_loss : 7.042839 / 6.604030 / 0.219405\tSaved\n",
      "Epoch : 5\tTrain_loss : 6.464904 / 5.949421 / 0.257741\tValid_loss : 6.046640 / 5.641171 / 0.202735\tSaved\n",
      "Epoch : 6\tTrain_loss : 5.573486 / 5.166434 / 0.203526\tValid_loss : 5.426550 / 5.054490 / 0.186030\tSaved\n",
      "Epoch : 7\tTrain_loss : 5.246583 / 4.669469 / 0.288557\tValid_loss : 5.047205 / 4.691004 / 0.178100\tSaved\n",
      "Epoch : 8\tTrain_loss : 4.749126 / 4.352423 / 0.198352\tValid_loss : 4.848585 / 4.465833 / 0.191376\tSaved\n",
      "Epoch : 9\tTrain_loss : 4.577038 / 4.207252 / 0.184893\tValid_loss : 4.655989 / 4.305415 / 0.175287\tSaved\n",
      "Epoch : 10\tTrain_loss : 4.546706 / 4.072197 / 0.237254\tValid_loss : 4.575429 / 4.207791 / 0.183819\tSaved\n",
      "Epoch : 11\tTrain_loss : 4.264512 / 3.983189 / 0.140661\tValid_loss : 4.492683 / 4.125581 / 0.183551\tSaved\n",
      "Epoch : 12\tTrain_loss : 4.138188 / 3.906148 / 0.116020\tValid_loss : 4.432359 / 4.079603 / 0.176378\tSaved\n",
      "Epoch : 13\tTrain_loss : 4.162055 / 3.836138 / 0.162959\tValid_loss : 4.407589 / 4.058048 / 0.174771\tSaved\n",
      "Epoch : 14\tTrain_loss : 4.115220 / 3.835055 / 0.140082\tValid_loss : 4.376182 / 4.013886 / 0.181148\tSaved\n",
      "Epoch : 15\tTrain_loss : 4.076367 / 3.811873 / 0.132247\tValid_loss : 4.332363 / 3.993683 / 0.169340\tSaved\n",
      "Epoch : 16\tTrain_loss : 4.034601 / 3.787017 / 0.123792\tValid_loss : 4.304544 / 3.981278 / 0.161633\tSaved\n",
      "Epoch : 17\tTrain_loss : 4.038904 / 3.762684 / 0.138110\tValid_loss : 4.286348 / 3.949582 / 0.168383\tSaved\n",
      "Epoch : 18\tTrain_loss : 4.014523 / 3.749895 / 0.132314\tValid_loss : 4.267843 / 3.935793 / 0.166025\tSaved\n",
      "Epoch : 19\tTrain_loss : 3.908161 / 3.723133 / 0.092514\tValid_loss : 4.252077 / 3.927283 / 0.162397\tSaved\n",
      "Epoch : 20\tTrain_loss : 3.893214 / 3.709492 / 0.091861\tValid_loss : 4.250288 / 3.929979 / 0.160154\tSaved\n",
      "Epoch : 21\tTrain_loss : 4.104736 / 3.723609 / 0.190563\tValid_loss : 4.231466 / 3.909528 / 0.160969\tSaved\n",
      "Epoch : 22\tTrain_loss : 4.219627 / 3.652341 / 0.283643\tValid_loss : 4.195768 / 3.897933 / 0.148917\tSaved\n",
      "Epoch : 23\tTrain_loss : 4.022991 / 3.676818 / 0.173087\tValid_loss : 4.195423 / 3.907652 / 0.143886\tSaved\n",
      "Epoch : 24\tTrain_loss : 4.062908 / 3.623793 / 0.219557\tValid_loss : 4.248367 / 3.901424 / 0.173472\tNo Saved\n",
      "Epoch : 25\tTrain_loss : 4.002125 / 3.647592 / 0.177266\tValid_loss : 4.231629 / 3.879020 / 0.176305\tNo Saved\n",
      "Epoch : 26\tTrain_loss : 3.904274 / 3.654962 / 0.124656\tValid_loss : 4.190299 / 3.867333 / 0.161483\tSaved\n",
      "Epoch : 27\tTrain_loss : 4.026619 / 3.608443 / 0.209088\tValid_loss : 4.190905 / 3.888795 / 0.151055\tNo Saved\n",
      "Epoch : 28\tTrain_loss : 3.870552 / 3.612692 / 0.128930\tValid_loss : 4.152881 / 3.856301 / 0.148290\tSaved\n",
      "Epoch : 29\tTrain_loss : 3.997396 / 3.665853 / 0.165772\tValid_loss : 4.170137 / 3.866953 / 0.151592\tNo Saved\n",
      "Epoch : 30\tTrain_loss : 3.841950 / 3.610900 / 0.115525\tValid_loss : 4.131999 / 3.840488 / 0.145755\tSaved\n",
      "Epoch : 31\tTrain_loss : 3.878956 / 3.594745 / 0.142105\tValid_loss : 4.143299 / 3.848606 / 0.147347\tNo Saved\n",
      "Epoch : 32\tTrain_loss : 3.923850 / 3.641429 / 0.141211\tValid_loss : 4.170844 / 3.871478 / 0.149683\tNo Saved\n",
      "Epoch : 33\tTrain_loss : 3.868607 / 3.594601 / 0.137003\tValid_loss : 4.158856 / 3.866321 / 0.146268\tNo Saved\n",
      "Epoch : 34\tTrain_loss : 4.039951 / 3.573775 / 0.233088\tValid_loss : 4.138225 / 3.861185 / 0.138520\tNo Saved\n",
      "Epoch : 35\tTrain_loss : 3.771526 / 3.571408 / 0.100059\tValid_loss : 4.113785 / 3.849195 / 0.132295\tSaved\n",
      "Epoch : 36\tTrain_loss : 3.811860 / 3.618268 / 0.096796\tValid_loss : 4.101231 / 3.835877 / 0.132677\tSaved\n",
      "Epoch : 37\tTrain_loss : 3.780617 / 3.602074 / 0.089272\tValid_loss : 4.114655 / 3.849769 / 0.132443\tNo Saved\n",
      "Epoch : 38\tTrain_loss : 3.846803 / 3.560937 / 0.142933\tValid_loss : 4.137943 / 3.856232 / 0.140856\tNo Saved\n",
      "Epoch : 39\tTrain_loss : 3.834073 / 3.563825 / 0.135124\tValid_loss : 4.157306 / 3.867940 / 0.144683\tNo Saved\n",
      "Epoch : 40\tTrain_loss : 3.850105 / 3.589805 / 0.130150\tValid_loss : 4.137863 / 3.849817 / 0.144023\tNo Saved\n",
      "Epoch : 41\tTrain_loss : 3.777816 / 3.565519 / 0.106149\tValid_loss : 4.130109 / 3.857418 / 0.136345\tNo Saved\n",
      "Epoch : 42\tTrain_loss : 3.786728 / 3.560815 / 0.112956\tValid_loss : 4.122252 / 3.847336 / 0.137458\tNo Saved\n",
      "Epoch : 43\tTrain_loss : 3.874553 / 3.543626 / 0.165463\tValid_loss : 4.166663 / 3.860651 / 0.153006\tNo Saved\n",
      "Epoch : 44\tTrain_loss : 3.819999 / 3.595516 / 0.112241\tValid_loss : 4.117966 / 3.848997 / 0.134485\tNo Saved\n",
      "Epoch : 45\tTrain_loss : 3.946368 / 3.568000 / 0.189184\tValid_loss : 4.133734 / 3.838442 / 0.147646\tNo Saved\n",
      "Epoch : 46\tTrain_loss : 3.777556 / 3.551751 / 0.112903\tValid_loss : 4.110384 / 3.840680 / 0.134852\tNo Saved\n",
      "Epoch : 47\tTrain_loss : 3.848491 / 3.575307 / 0.136592\tValid_loss : 4.096958 / 3.833894 / 0.131532\tSaved\n",
      "Epoch : 48\tTrain_loss : 3.801770 / 3.586913 / 0.107428\tValid_loss : 4.126889 / 3.856036 / 0.135426\tNo Saved\n",
      "Epoch : 49\tTrain_loss : 3.831710 / 3.516074 / 0.157818\tValid_loss : 4.119648 / 3.843048 / 0.138300\tNo Saved\n",
      "Epoch : 50\tTrain_loss : 3.766359 / 3.550852 / 0.107753\tValid_loss : 4.110285 / 3.831744 / 0.139270\tNo Saved\n",
      "Epoch : 51\tTrain_loss : 3.872282 / 3.554522 / 0.158880\tValid_loss : 4.154084 / 3.861323 / 0.146381\tNo Saved\n",
      "Epoch : 52\tTrain_loss : 4.055356 / 3.571318 / 0.242019\tValid_loss : 4.118710 / 3.843186 / 0.137762\tNo Saved\n",
      "Epoch : 53\tTrain_loss : 3.853496 / 3.564744 / 0.144376\tValid_loss : 4.086396 / 3.827373 / 0.129511\tSaved\n",
      "Epoch : 54\tTrain_loss : 3.790478 / 3.538888 / 0.125795\tValid_loss : 4.153003 / 3.832888 / 0.160057\tNo Saved\n",
      "Epoch : 55\tTrain_loss : 3.814560 / 3.526387 / 0.144087\tValid_loss : 4.155811 / 3.835091 / 0.160360\tNo Saved\n",
      "Epoch : 56\tTrain_loss : 3.813444 / 3.544952 / 0.134246\tValid_loss : 4.119244 / 3.824976 / 0.147134\tNo Saved\n",
      "Epoch : 57\tTrain_loss : 3.811527 / 3.506644 / 0.152442\tValid_loss : 4.118083 / 3.831085 / 0.143499\tNo Saved\n",
      "Epoch : 58\tTrain_loss : 3.845542 / 3.544011 / 0.150765\tValid_loss : 4.127408 / 3.842595 / 0.142407\tNo Saved\n",
      "Epoch : 59\tTrain_loss : 3.989086 / 3.539225 / 0.224930\tValid_loss : 4.099893 / 3.826808 / 0.136543\tNo Saved\n",
      "Epoch : 60\tTrain_loss : 3.771736 / 3.543381 / 0.114177\tValid_loss : 4.113202 / 3.848902 / 0.132150\tNo Saved\n",
      "Epoch : 61\tTrain_loss : 3.806502 / 3.567109 / 0.119697\tValid_loss : 4.124752 / 3.831172 / 0.146790\tNo Saved\n",
      "Epoch : 62\tTrain_loss : 3.723462 / 3.532624 / 0.095419\tValid_loss : 4.117700 / 3.834087 / 0.141807\tNo Saved\n",
      "Epoch : 63\tTrain_loss : 3.836610 / 3.512302 / 0.162154\tValid_loss : 4.126477 / 3.851412 / 0.137533\tNo Saved\n",
      "Epoch : 64\tTrain_loss : 3.729525 / 3.524945 / 0.102290\tValid_loss : 4.136239 / 3.850213 / 0.143013\tNo Saved\n",
      "Epoch : 65\tTrain_loss : 3.701287 / 3.513713 / 0.093787\tValid_loss : 4.119556 / 3.818937 / 0.150310\tNo Saved\n",
      "Epoch : 66\tTrain_loss : 3.678562 / 3.504912 / 0.086825\tValid_loss : 4.113990 / 3.840286 / 0.136852\tNo Saved\n",
      "Epoch : 67\tTrain_loss : 3.659060 / 3.514735 / 0.072162\tValid_loss : 4.098956 / 3.832146 / 0.133405\tNo Saved\n",
      "Epoch : 68\tTrain_loss : 3.682759 / 3.485497 / 0.098631\tValid_loss : 4.110005 / 3.834090 / 0.137958\tNo Saved\n",
      "Epoch : 69\tTrain_loss : 3.635707 / 3.486144 / 0.074782\tValid_loss : 4.132699 / 3.829380 / 0.151659\tNo Saved\n",
      "Epoch : 70\tTrain_loss : 3.746811 / 3.490818 / 0.127996\tValid_loss : 4.112247 / 3.814917 / 0.148665\tNo Saved\n",
      "Epoch : 71\tTrain_loss : 3.715775 / 3.551416 / 0.082180\tValid_loss : 4.121407 / 3.836650 / 0.142378\tNo Saved\n",
      "Epoch : 72\tTrain_loss : 3.773299 / 3.488176 / 0.142562\tValid_loss : 4.128811 / 3.840614 / 0.144098\tNo Saved\n",
      "Epoch : 73\tTrain_loss : 3.839288 / 3.508251 / 0.165519\tValid_loss : 4.147490 / 3.839060 / 0.154215\tNo Saved\n",
      "Epoch : 74\tTrain_loss : 3.755482 / 3.527874 / 0.113804\tValid_loss : 4.116525 / 3.834232 / 0.141146\tNo Saved\n",
      "Epoch : 75\tTrain_loss : 3.654710 / 3.466607 / 0.094052\tValid_loss : 4.111773 / 3.833052 / 0.139361\tNo Saved\n",
      "Epoch : 76\tTrain_loss : 3.825998 / 3.487542 / 0.169228\tValid_loss : 4.110214 / 3.828214 / 0.141000\tNo Saved\n",
      "Epoch : 77\tTrain_loss : 3.737933 / 3.488870 / 0.124531\tValid_loss : 4.113952 / 3.817508 / 0.148222\tNo Saved\n",
      "Epoch : 78\tTrain_loss : 3.671747 / 3.461986 / 0.104880\tValid_loss : 4.103965 / 3.827309 / 0.138328\tNo Saved\n",
      "Epoch : 79\tTrain_loss : 3.837479 / 3.517610 / 0.159935\tValid_loss : 4.124390 / 3.836155 / 0.144118\tNo Saved\n",
      "Epoch : 80\tTrain_loss : 3.687322 / 3.493286 / 0.097018\tValid_loss : 4.106177 / 3.822828 / 0.141675\tNo Saved\n",
      "Epoch : 81\tTrain_loss : 3.686879 / 3.440634 / 0.123123\tValid_loss : 4.109264 / 3.822375 / 0.143445\tNo Saved\n",
      "Epoch : 82\tTrain_loss : 3.654072 / 3.451974 / 0.101049\tValid_loss : 4.114821 / 3.835942 / 0.139439\tNo Saved\n",
      "Epoch : 83\tTrain_loss : 3.689033 / 3.486018 / 0.101508\tValid_loss : 4.131822 / 3.851130 / 0.140346\tNo Saved\n",
      "Epoch : 84\tTrain_loss : 3.692357 / 3.476397 / 0.107980\tValid_loss : 4.105744 / 3.822690 / 0.141527\tNo Saved\n",
      "Epoch : 85\tTrain_loss : 3.794865 / 3.475434 / 0.159716\tValid_loss : 4.098692 / 3.839596 / 0.129548\tNo Saved\n",
      "Epoch : 86\tTrain_loss : 3.801322 / 3.502518 / 0.149402\tValid_loss : 4.106544 / 3.825603 / 0.140471\tNo Saved\n",
      "Epoch : 87\tTrain_loss : 3.721512 / 3.494395 / 0.113558\tValid_loss : 4.087897 / 3.821454 / 0.133222\tNo Saved\n",
      "Epoch : 88\tTrain_loss : 3.702056 / 3.482328 / 0.109864\tValid_loss : 4.147937 / 3.846492 / 0.150723\tNo Saved\n",
      "Epoch : 89\tTrain_loss : 3.740199 / 3.503082 / 0.118558\tValid_loss : 4.128848 / 3.830018 / 0.149415\tNo Saved\n",
      "Epoch : 90\tTrain_loss : 3.622828 / 3.436504 / 0.093162\tValid_loss : 4.113338 / 3.831246 / 0.141046\tNo Saved\n",
      "Epoch : 91\tTrain_loss : 3.615126 / 3.434183 / 0.090472\tValid_loss : 4.100472 / 3.830216 / 0.135128\tNo Saved\n",
      "Epoch : 92\tTrain_loss : 3.694803 / 3.446403 / 0.124200\tValid_loss : 4.112263 / 3.839273 / 0.136495\tNo Saved\n",
      "Epoch : 93\tTrain_loss : 3.731292 / 3.516203 / 0.107545\tValid_loss : 4.095045 / 3.821464 / 0.136791\tNo Saved\n",
      "Epoch : 94\tTrain_loss : 3.816232 / 3.435580 / 0.190326\tValid_loss : 4.087847 / 3.822871 / 0.132488\tNo Saved\n",
      "Epoch : 95\tTrain_loss : 3.699722 / 3.498074 / 0.100824\tValid_loss : 4.084933 / 3.818868 / 0.133033\tSaved\n",
      "Epoch : 96\tTrain_loss : 3.822570 / 3.458582 / 0.181994\tValid_loss : 4.090558 / 3.823522 / 0.133518\tNo Saved\n",
      "Epoch : 97\tTrain_loss : 3.798407 / 3.491577 / 0.153415\tValid_loss : 4.095388 / 3.836432 / 0.129478\tNo Saved\n",
      "Epoch : 98\tTrain_loss : 3.607273 / 3.436254 / 0.085510\tValid_loss : 4.118583 / 3.827427 / 0.145578\tNo Saved\n",
      "Epoch : 99\tTrain_loss : 3.658406 / 3.485494 / 0.086456\tValid_loss : 4.158005 / 3.858414 / 0.149795\tNo Saved\n",
      "Epoch : 100\tTrain_loss : 3.764940 / 3.482795 / 0.141073\tValid_loss : 4.117871 / 3.826570 / 0.145650\tNo Saved\n",
      "Epoch : 101\tTrain_loss : 3.614523 / 3.429474 / 0.092525\tValid_loss : 4.120750 / 3.837090 / 0.141830\tNo Saved\n",
      "Epoch : 102\tTrain_loss : 3.783312 / 3.440700 / 0.171306\tValid_loss : 4.107958 / 3.830176 / 0.138891\tNo Saved\n",
      "Epoch : 103\tTrain_loss : 3.659780 / 3.440213 / 0.109783\tValid_loss : 4.124068 / 3.834220 / 0.144924\tNo Saved\n",
      "Epoch : 104\tTrain_loss : 3.647909 / 3.436026 / 0.105941\tValid_loss : 4.108456 / 3.835726 / 0.136365\tNo Saved\n",
      "Epoch : 105\tTrain_loss : 3.680613 / 3.433706 / 0.123454\tValid_loss : 4.094111 / 3.823290 / 0.135411\tNo Saved\n",
      "Epoch : 106\tTrain_loss : 3.599858 / 3.434923 / 0.082468\tValid_loss : 4.089581 / 3.824335 / 0.132623\tNo Saved\n",
      "Epoch : 107\tTrain_loss : 3.665689 / 3.434623 / 0.115533\tValid_loss : 4.128607 / 3.846538 / 0.141035\tNo Saved\n",
      "Epoch : 108\tTrain_loss : 3.702622 / 3.482117 / 0.110252\tValid_loss : 4.109166 / 3.832787 / 0.138190\tNo Saved\n",
      "Epoch : 109\tTrain_loss : 3.619303 / 3.430890 / 0.094207\tValid_loss : 4.115493 / 3.821934 / 0.146780\tNo Saved\n",
      "Epoch : 110\tTrain_loss : 3.856506 / 3.449117 / 0.203694\tValid_loss : 4.131486 / 3.835357 / 0.148064\tNo Saved\n",
      "Epoch : 111\tTrain_loss : 3.630032 / 3.419496 / 0.105268\tValid_loss : 4.095343 / 3.830303 / 0.132520\tNo Saved\n",
      "Epoch : 112\tTrain_loss : 3.608535 / 3.447462 / 0.080536\tValid_loss : 4.106780 / 3.833532 / 0.136624\tNo Saved\n",
      "Epoch : 113\tTrain_loss : 3.671143 / 3.450628 / 0.110258\tValid_loss : 4.103304 / 3.829994 / 0.136655\tNo Saved\n",
      "Epoch : 114\tTrain_loss : 3.622801 / 3.442433 / 0.090184\tValid_loss : 4.110516 / 3.846564 / 0.131976\tNo Saved\n",
      "Epoch : 115\tTrain_loss : 3.569295 / 3.422365 / 0.073465\tValid_loss : 4.126264 / 3.852394 / 0.136935\tNo Saved\n",
      "Epoch : 116\tTrain_loss : 3.633106 / 3.423523 / 0.104791\tValid_loss : 4.094281 / 3.826144 / 0.134069\tNo Saved\n",
      "Epoch : 117\tTrain_loss : 3.666839 / 3.478510 / 0.094165\tValid_loss : 4.104491 / 3.835641 / 0.134425\tNo Saved\n",
      "Epoch : 118\tTrain_loss : 3.647220 / 3.478257 / 0.084482\tValid_loss : 4.091059 / 3.836723 / 0.127168\tNo Saved\n",
      "Epoch : 119\tTrain_loss : 3.624096 / 3.436287 / 0.093905\tValid_loss : 4.115350 / 3.841246 / 0.137052\tNo Saved\n",
      "Epoch : 120\tTrain_loss : 3.672931 / 3.465052 / 0.103939\tValid_loss : 4.097090 / 3.833396 / 0.131847\tNo Saved\n",
      "Epoch : 121\tTrain_loss : 3.682034 / 3.446719 / 0.117657\tValid_loss : 4.075709 / 3.817966 / 0.128871\tSaved\n",
      "Epoch : 122\tTrain_loss : 3.625156 / 3.400799 / 0.112179\tValid_loss : 4.100577 / 3.834627 / 0.132975\tNo Saved\n",
      "Epoch : 123\tTrain_loss : 3.606923 / 3.439465 / 0.083729\tValid_loss : 4.117308 / 3.830173 / 0.143567\tNo Saved\n",
      "Epoch : 124\tTrain_loss : 3.619128 / 3.436258 / 0.091435\tValid_loss : 4.118653 / 3.831624 / 0.143515\tNo Saved\n",
      "Epoch : 125\tTrain_loss : 3.729157 / 3.467639 / 0.130759\tValid_loss : 4.106573 / 3.827161 / 0.139706\tNo Saved\n",
      "Epoch : 126\tTrain_loss : 3.576209 / 3.418310 / 0.078949\tValid_loss : 4.092140 / 3.828452 / 0.131844\tNo Saved\n",
      "Epoch : 127\tTrain_loss : 3.612468 / 3.432151 / 0.090158\tValid_loss : 4.105173 / 3.838756 / 0.133209\tNo Saved\n",
      "Epoch : 128\tTrain_loss : 3.643804 / 3.445888 / 0.098958\tValid_loss : 4.094042 / 3.828949 / 0.132546\tNo Saved\n",
      "Epoch : 129\tTrain_loss : 3.628247 / 3.437968 / 0.095139\tValid_loss : 4.096442 / 3.830255 / 0.133094\tNo Saved\n",
      "Epoch : 130\tTrain_loss : 3.627840 / 3.431687 / 0.098077\tValid_loss : 4.087519 / 3.829194 / 0.129162\tNo Saved\n",
      "Epoch : 131\tTrain_loss : 3.616941 / 3.408362 / 0.104290\tValid_loss : 4.118766 / 3.840504 / 0.139131\tNo Saved\n",
      "Epoch : 132\tTrain_loss : 3.834235 / 3.431648 / 0.201294\tValid_loss : 4.076283 / 3.826329 / 0.124977\tNo Saved\n",
      "Epoch : 133\tTrain_loss : 3.759246 / 3.394236 / 0.182505\tValid_loss : 4.089975 / 3.836951 / 0.126512\tNo Saved\n",
      "Epoch : 134\tTrain_loss : 3.680645 / 3.445752 / 0.117446\tValid_loss : 4.100187 / 3.834799 / 0.132694\tNo Saved\n",
      "Epoch : 135\tTrain_loss : 3.652642 / 3.451415 / 0.100614\tValid_loss : 4.093962 / 3.828354 / 0.132804\tNo Saved\n",
      "Epoch : 136\tTrain_loss : 3.639202 / 3.426121 / 0.106540\tValid_loss : 4.096694 / 3.827430 / 0.134632\tNo Saved\n",
      "Epoch : 137\tTrain_loss : 3.555912 / 3.418455 / 0.068728\tValid_loss : 4.089289 / 3.826742 / 0.131274\tNo Saved\n",
      "Epoch : 138\tTrain_loss : 3.674040 / 3.417634 / 0.128203\tValid_loss : 4.105999 / 3.825119 / 0.140440\tNo Saved\n",
      "Epoch : 139\tTrain_loss : 3.646267 / 3.403307 / 0.121480\tValid_loss : 4.121404 / 3.827457 / 0.146974\tNo Saved\n",
      "Epoch : 140\tTrain_loss : 3.931341 / 3.439940 / 0.245700\tValid_loss : 4.092787 / 3.828160 / 0.132313\tNo Saved\n",
      "Epoch : 141\tTrain_loss : 3.711831 / 3.431084 / 0.140374\tValid_loss : 4.119372 / 3.847420 / 0.135976\tNo Saved\n",
      "Epoch : 142\tTrain_loss : 3.574611 / 3.383664 / 0.095474\tValid_loss : 4.130456 / 3.840351 / 0.145053\tNo Saved\n",
      "Epoch : 143\tTrain_loss : 3.590864 / 3.418776 / 0.086044\tValid_loss : 4.110185 / 3.839734 / 0.135226\tNo Saved\n",
      "Epoch : 144\tTrain_loss : 3.757312 / 3.443942 / 0.156685\tValid_loss : 4.113973 / 3.842184 / 0.135895\tNo Saved\n",
      "Epoch : 145\tTrain_loss : 3.715267 / 3.434734 / 0.140266\tValid_loss : 4.111617 / 3.849923 / 0.130847\tNo Saved\n",
      "Epoch : 146\tTrain_loss : 3.559325 / 3.407343 / 0.075991\tValid_loss : 4.084952 / 3.836500 / 0.124226\tNo Saved\n",
      "Epoch : 147\tTrain_loss : 3.596149 / 3.391878 / 0.102135\tValid_loss : 4.108056 / 3.827181 / 0.140438\tNo Saved\n",
      "Epoch : 148\tTrain_loss : 3.582993 / 3.398412 / 0.092291\tValid_loss : 4.097593 / 3.837044 / 0.130275\tNo Saved\n",
      "Epoch : 149\tTrain_loss : 3.779853 / 3.427050 / 0.176402\tValid_loss : 4.118452 / 3.843987 / 0.137232\tNo Saved\n",
      "Epoch : 150\tTrain_loss : 3.662528 / 3.444845 / 0.108842\tValid_loss : 4.120946 / 3.847022 / 0.136962\tNo Saved\n",
      "Epoch : 151\tTrain_loss : 3.626630 / 3.408534 / 0.109048\tValid_loss : 4.120329 / 3.841689 / 0.139320\tNo Saved\n",
      "Epoch : 152\tTrain_loss : 3.538385 / 3.377887 / 0.080249\tValid_loss : 4.104815 / 3.841287 / 0.131764\tNo Saved\n",
      "Epoch : 153\tTrain_loss : 3.540875 / 3.386983 / 0.076946\tValid_loss : 4.104892 / 3.838213 / 0.133339\tNo Saved\n",
      "Epoch : 154\tTrain_loss : 3.538911 / 3.346267 / 0.096322\tValid_loss : 4.103432 / 3.831261 / 0.136086\tNo Saved\n",
      "Epoch : 155\tTrain_loss : 3.588563 / 3.384148 / 0.102207\tValid_loss : 4.095648 / 3.845990 / 0.124829\tNo Saved\n",
      "Epoch : 156\tTrain_loss : 3.561870 / 3.384158 / 0.088856\tValid_loss : 4.109217 / 3.835764 / 0.136726\tNo Saved\n",
      "Epoch : 157\tTrain_loss : 3.568740 / 3.407354 / 0.080693\tValid_loss : 4.129812 / 3.858292 / 0.135760\tNo Saved\n",
      "Epoch : 158\tTrain_loss : 3.530919 / 3.367202 / 0.081858\tValid_loss : 4.101741 / 3.843482 / 0.129129\tNo Saved\n",
      "Epoch : 159\tTrain_loss : 3.644694 / 3.406519 / 0.119088\tValid_loss : 4.083284 / 3.842276 / 0.120504\tNo Saved\n",
      "Epoch : 160\tTrain_loss : 3.711791 / 3.420029 / 0.145881\tValid_loss : 4.135163 / 3.858389 / 0.138387\tNo Saved\n",
      "Epoch : 161\tTrain_loss : 3.625791 / 3.347386 / 0.139202\tValid_loss : 4.128347 / 3.848255 / 0.140046\tNo Saved\n",
      "Epoch : 162\tTrain_loss : 3.551063 / 3.375050 / 0.088007\tValid_loss : 4.105989 / 3.849466 / 0.128261\tNo Saved\n",
      "Epoch : 163\tTrain_loss : 3.591338 / 3.439808 / 0.075765\tValid_loss : 4.109399 / 3.851367 / 0.129016\tNo Saved\n",
      "Epoch : 164\tTrain_loss : 3.514656 / 3.367469 / 0.073594\tValid_loss : 4.116144 / 3.862675 / 0.126734\tNo Saved\n",
      "Epoch : 165\tTrain_loss : 3.531892 / 3.358077 / 0.086908\tValid_loss : 4.105917 / 3.859451 / 0.123233\tNo Saved\n",
      "Epoch : 166\tTrain_loss : 3.605775 / 3.346106 / 0.129835\tValid_loss : 4.106331 / 3.851964 / 0.127183\tNo Saved\n",
      "Epoch : 167\tTrain_loss : 3.544980 / 3.382725 / 0.081127\tValid_loss : 4.103446 / 3.853180 / 0.125133\tNo Saved\n",
      "Epoch : 168\tTrain_loss : 3.505536 / 3.365328 / 0.070104\tValid_loss : 4.113447 / 3.851456 / 0.130996\tNo Saved\n",
      "Epoch : 169\tTrain_loss : 3.563567 / 3.398133 / 0.082717\tValid_loss : 4.095421 / 3.849828 / 0.122796\tNo Saved\n",
      "Epoch : 170\tTrain_loss : 3.831140 / 3.365368 / 0.232886\tValid_loss : 4.095456 / 3.846195 / 0.124630\tNo Saved\n",
      "Epoch : 171\tTrain_loss : 3.603833 / 3.412585 / 0.095624\tValid_loss : 4.101321 / 3.839100 / 0.131111\tNo Saved\n",
      "Epoch : 172\tTrain_loss : 3.563449 / 3.391753 / 0.085848\tValid_loss : 4.078227 / 3.830938 / 0.123644\tNo Saved\n",
      "Epoch : 173\tTrain_loss : 3.510324 / 3.373257 / 0.068533\tValid_loss : 4.095680 / 3.849971 / 0.122854\tNo Saved\n",
      "Epoch : 174\tTrain_loss : 3.584753 / 3.392800 / 0.095976\tValid_loss : 4.101092 / 3.852070 / 0.124511\tNo Saved\n",
      "Epoch : 175\tTrain_loss : 3.574204 / 3.369677 / 0.102263\tValid_loss : 4.100923 / 3.833582 / 0.133671\tNo Saved\n",
      "Epoch : 176\tTrain_loss : 3.580832 / 3.365485 / 0.107674\tValid_loss : 4.109494 / 3.848777 / 0.130359\tNo Saved\n",
      "Epoch : 177\tTrain_loss : 3.737393 / 3.434791 / 0.151301\tValid_loss : 4.144274 / 3.852427 / 0.145923\tNo Saved\n",
      "Epoch : 178\tTrain_loss : 3.537670 / 3.406210 / 0.065730\tValid_loss : 4.113763 / 3.849817 / 0.131973\tNo Saved\n",
      "Epoch : 179\tTrain_loss : 3.542787 / 3.370700 / 0.086044\tValid_loss : 4.116979 / 3.854449 / 0.131265\tNo Saved\n",
      "Epoch : 180\tTrain_loss : 3.593369 / 3.383392 / 0.104988\tValid_loss : 4.099729 / 3.853345 / 0.123192\tNo Saved\n",
      "Epoch : 181\tTrain_loss : 3.599903 / 3.412897 / 0.093503\tValid_loss : 4.135937 / 3.849995 / 0.142971\tNo Saved\n",
      "Epoch : 182\tTrain_loss : 3.488265 / 3.326676 / 0.080795\tValid_loss : 4.135816 / 3.855155 / 0.140331\tNo Saved\n",
      "Epoch : 183\tTrain_loss : 3.500114 / 3.357969 / 0.071072\tValid_loss : 4.134483 / 3.868471 / 0.133006\tNo Saved\n",
      "Epoch : 184\tTrain_loss : 3.510526 / 3.366112 / 0.072207\tValid_loss : 4.129221 / 3.878400 / 0.125410\tNo Saved\n",
      "Epoch : 185\tTrain_loss : 3.519697 / 3.374821 / 0.072438\tValid_loss : 4.112864 / 3.856872 / 0.127996\tNo Saved\n",
      "Epoch : 186\tTrain_loss : 3.684523 / 3.389430 / 0.147547\tValid_loss : 4.133326 / 3.864571 / 0.134377\tNo Saved\n",
      "Epoch : 187\tTrain_loss : 3.490917 / 3.338000 / 0.076459\tValid_loss : 4.116259 / 3.856082 / 0.130088\tNo Saved\n",
      "Epoch : 188\tTrain_loss : 3.537806 / 3.375272 / 0.081267\tValid_loss : 4.110262 / 3.867593 / 0.121335\tNo Saved\n",
      "Epoch : 189\tTrain_loss : 3.628784 / 3.351164 / 0.138810\tValid_loss : 4.115526 / 3.867093 / 0.124216\tNo Saved\n",
      "Epoch : 190\tTrain_loss : 3.539933 / 3.360558 / 0.089688\tValid_loss : 4.132172 / 3.877263 / 0.127455\tNo Saved\n",
      "Epoch : 191\tTrain_loss : 3.524404 / 3.393356 / 0.065524\tValid_loss : 4.118035 / 3.865633 / 0.126201\tNo Saved\n",
      "Epoch : 192\tTrain_loss : 3.568213 / 3.362561 / 0.102826\tValid_loss : 4.101360 / 3.854435 / 0.123462\tNo Saved\n",
      "Epoch : 193\tTrain_loss : 3.538778 / 3.360870 / 0.088954\tValid_loss : 4.138434 / 3.880615 / 0.128909\tNo Saved\n",
      "Epoch : 194\tTrain_loss : 3.706143 / 3.323412 / 0.191366\tValid_loss : 4.110999 / 3.859720 / 0.125640\tNo Saved\n",
      "Epoch : 195\tTrain_loss : 3.486279 / 3.321021 / 0.082629\tValid_loss : 4.107290 / 3.871096 / 0.118097\tNo Saved\n",
      "Epoch : 196\tTrain_loss : 3.515862 / 3.360145 / 0.077858\tValid_loss : 4.127678 / 3.877541 / 0.125068\tNo Saved\n",
      "Epoch : 197\tTrain_loss : 3.484765 / 3.308954 / 0.087906\tValid_loss : 4.128221 / 3.876198 / 0.126011\tNo Saved\n",
      "Epoch : 198\tTrain_loss : 3.530656 / 3.341820 / 0.094418\tValid_loss : 4.131143 / 3.876823 / 0.127160\tNo Saved\n",
      "Epoch : 199\tTrain_loss : 3.726194 / 3.374777 / 0.175708\tValid_loss : 4.134483 / 3.854524 / 0.139979\tNo Saved\n",
      "Epoch : 200\tTrain_loss : 3.494174 / 3.322776 / 0.085699\tValid_loss : 4.114016 / 3.867495 / 0.123260\tNo Saved\n",
      "Training Model 2 of 3 is Completed...\n",
      "Data is Ready...\n",
      "Model 3 is built...\n",
      "Model 3 is training\n",
      "Epoch : 1\tTrain_loss : 23.714191 / 21.660300 / 1.026946\tValid_loss : 18.042207 / 16.937328 / 0.552439\tSaved\n",
      "Epoch : 2\tTrain_loss : 15.031445 / 14.271421 / 0.380012\tValid_loss : 12.706103 / 11.824236 / 0.440934\tSaved\n",
      "Epoch : 3\tTrain_loss : 10.575439 / 10.115892 / 0.229773\tValid_loss : 9.378008 / 8.694900 / 0.341554\tSaved\n",
      "Epoch : 4\tTrain_loss : 8.019699 / 7.657911 / 0.180894\tValid_loss : 7.494217 / 6.873883 / 0.310167\tSaved\n",
      "Epoch : 5\tTrain_loss : 6.741662 / 6.235509 / 0.253076\tValid_loss : 6.418512 / 5.815711 / 0.301401\tSaved\n",
      "Epoch : 6\tTrain_loss : 5.778638 / 5.366780 / 0.205929\tValid_loss : 5.790482 / 5.192508 / 0.298987\tSaved\n",
      "Epoch : 7\tTrain_loss : 5.344568 / 4.841587 / 0.251490\tValid_loss : 5.346754 / 4.795472 / 0.275641\tSaved\n",
      "Epoch : 8\tTrain_loss : 4.874723 / 4.475157 / 0.199783\tValid_loss : 5.077541 / 4.540319 / 0.268611\tSaved\n",
      "Epoch : 9\tTrain_loss : 4.660123 / 4.270950 / 0.194586\tValid_loss : 4.966456 / 4.390005 / 0.288225\tSaved\n",
      "Epoch : 10\tTrain_loss : 4.421678 / 4.135738 / 0.142970\tValid_loss : 4.896358 / 4.286781 / 0.304789\tSaved\n",
      "Epoch : 11\tTrain_loss : 4.396258 / 4.048145 / 0.174056\tValid_loss : 4.792554 / 4.214716 / 0.288919\tSaved\n",
      "Epoch : 12\tTrain_loss : 4.350779 / 4.014917 / 0.167931\tValid_loss : 4.744329 / 4.163697 / 0.290316\tSaved\n",
      "Epoch : 13\tTrain_loss : 4.258561 / 3.898629 / 0.179966\tValid_loss : 4.685197 / 4.106089 / 0.289554\tSaved\n",
      "Epoch : 14\tTrain_loss : 4.146799 / 3.864150 / 0.141324\tValid_loss : 4.671874 / 4.081823 / 0.295025\tSaved\n",
      "Epoch : 15\tTrain_loss : 4.067862 / 3.843537 / 0.112163\tValid_loss : 4.641859 / 4.063671 / 0.289094\tSaved\n",
      "Epoch : 16\tTrain_loss : 4.199895 / 3.840426 / 0.179734\tValid_loss : 4.573014 / 4.047670 / 0.262672\tSaved\n",
      "Epoch : 17\tTrain_loss : 4.025502 / 3.809096 / 0.108203\tValid_loss : 4.528801 / 4.033068 / 0.247866\tSaved\n",
      "Epoch : 18\tTrain_loss : 3.981350 / 3.749454 / 0.115948\tValid_loss : 4.586838 / 4.015994 / 0.285422\tNo Saved\n",
      "Epoch : 19\tTrain_loss : 4.046373 / 3.781331 / 0.132521\tValid_loss : 4.592953 / 4.013457 / 0.289748\tNo Saved\n",
      "Epoch : 20\tTrain_loss : 3.832829 / 3.639689 / 0.096570\tValid_loss : 4.552905 / 3.983121 / 0.284892\tNo Saved\n",
      "Epoch : 21\tTrain_loss : 3.985579 / 3.694723 / 0.145428\tValid_loss : 4.560506 / 3.972158 / 0.294174\tNo Saved\n",
      "Epoch : 22\tTrain_loss : 3.893240 / 3.730156 / 0.081542\tValid_loss : 4.539224 / 3.981258 / 0.278983\tNo Saved\n",
      "Epoch : 23\tTrain_loss : 3.851781 / 3.668325 / 0.091728\tValid_loss : 4.462039 / 3.949015 / 0.256512\tSaved\n",
      "Epoch : 24\tTrain_loss : 4.000015 / 3.691285 / 0.154365\tValid_loss : 4.550444 / 3.972669 / 0.288888\tNo Saved\n",
      "Epoch : 25\tTrain_loss : 4.232440 / 3.669015 / 0.281713\tValid_loss : 4.488892 / 3.962479 / 0.263207\tNo Saved\n",
      "Epoch : 26\tTrain_loss : 4.110221 / 3.699840 / 0.205191\tValid_loss : 4.572567 / 3.950993 / 0.310787\tNo Saved\n",
      "Epoch : 27\tTrain_loss : 3.846646 / 3.654115 / 0.096265\tValid_loss : 4.612985 / 3.968540 / 0.322222\tNo Saved\n",
      "Epoch : 28\tTrain_loss : 3.847227 / 3.634078 / 0.106574\tValid_loss : 4.597191 / 3.943785 / 0.326703\tNo Saved\n",
      "Epoch : 29\tTrain_loss : 3.846350 / 3.615386 / 0.115482\tValid_loss : 4.526956 / 3.947368 / 0.289794\tNo Saved\n",
      "Epoch : 30\tTrain_loss : 3.775228 / 3.620147 / 0.077541\tValid_loss : 4.485927 / 3.923709 / 0.281109\tNo Saved\n",
      "Epoch : 31\tTrain_loss : 3.876808 / 3.655124 / 0.110842\tValid_loss : 4.487105 / 3.914061 / 0.286522\tNo Saved\n",
      "Epoch : 32\tTrain_loss : 3.862848 / 3.621924 / 0.120462\tValid_loss : 4.577501 / 3.937910 / 0.319795\tNo Saved\n",
      "Epoch : 33\tTrain_loss : 3.956542 / 3.636833 / 0.159855\tValid_loss : 4.544480 / 3.949180 / 0.297650\tNo Saved\n",
      "Epoch : 34\tTrain_loss : 3.958694 / 3.635844 / 0.161425\tValid_loss : 4.474659 / 3.917138 / 0.278761\tNo Saved\n",
      "Epoch : 35\tTrain_loss : 3.949057 / 3.622924 / 0.163066\tValid_loss : 4.522288 / 3.918424 / 0.301932\tNo Saved\n",
      "Epoch : 36\tTrain_loss : 3.833652 / 3.581388 / 0.126132\tValid_loss : 4.547539 / 3.922082 / 0.312729\tNo Saved\n",
      "Epoch : 37\tTrain_loss : 3.815098 / 3.641922 / 0.086588\tValid_loss : 4.501924 / 3.930255 / 0.285835\tNo Saved\n",
      "Epoch : 38\tTrain_loss : 3.880145 / 3.650868 / 0.114639\tValid_loss : 4.433572 / 3.927564 / 0.253004\tSaved\n",
      "Epoch : 39\tTrain_loss : 3.805812 / 3.613169 / 0.096321\tValid_loss : 4.490732 / 3.924266 / 0.283233\tNo Saved\n",
      "Epoch : 40\tTrain_loss : 3.874085 / 3.593183 / 0.140451\tValid_loss : 4.450231 / 3.916426 / 0.266902\tNo Saved\n",
      "Epoch : 41\tTrain_loss : 3.860661 / 3.614041 / 0.123310\tValid_loss : 4.498485 / 3.916880 / 0.290803\tNo Saved\n",
      "Epoch : 42\tTrain_loss : 3.758204 / 3.588075 / 0.085064\tValid_loss : 4.452620 / 3.908595 / 0.272012\tNo Saved\n",
      "Epoch : 43\tTrain_loss : 3.724741 / 3.578180 / 0.073280\tValid_loss : 4.467916 / 3.921446 / 0.273235\tNo Saved\n",
      "Epoch : 44\tTrain_loss : 3.787313 / 3.612055 / 0.087629\tValid_loss : 4.490069 / 3.927341 / 0.281364\tNo Saved\n",
      "Epoch : 45\tTrain_loss : 3.851641 / 3.593316 / 0.129163\tValid_loss : 4.571079 / 3.921822 / 0.324629\tNo Saved\n",
      "Epoch : 46\tTrain_loss : 3.807715 / 3.563670 / 0.122022\tValid_loss : 4.472133 / 3.914685 / 0.278724\tNo Saved\n",
      "Epoch : 47\tTrain_loss : 3.700340 / 3.557720 / 0.071310\tValid_loss : 4.479328 / 3.924655 / 0.277336\tNo Saved\n",
      "Epoch : 48\tTrain_loss : 3.741877 / 3.549729 / 0.096074\tValid_loss : 4.480536 / 3.903964 / 0.288286\tNo Saved\n",
      "Epoch : 49\tTrain_loss : 3.689196 / 3.558227 / 0.065485\tValid_loss : 4.494164 / 3.911034 / 0.291565\tNo Saved\n",
      "Epoch : 50\tTrain_loss : 3.909840 / 3.554529 / 0.177656\tValid_loss : 4.459292 / 3.894631 / 0.282330\tNo Saved\n",
      "Epoch : 51\tTrain_loss : 3.700073 / 3.507906 / 0.096083\tValid_loss : 4.489305 / 3.906619 / 0.291343\tNo Saved\n",
      "Epoch : 52\tTrain_loss : 3.743221 / 3.530474 / 0.106373\tValid_loss : 4.563632 / 3.917715 / 0.322958\tNo Saved\n",
      "Epoch : 53\tTrain_loss : 3.723498 / 3.563740 / 0.079879\tValid_loss : 4.518379 / 3.906804 / 0.305788\tNo Saved\n",
      "Epoch : 54\tTrain_loss : 3.737129 / 3.568747 / 0.084191\tValid_loss : 4.526212 / 3.913388 / 0.306412\tNo Saved\n",
      "Epoch : 55\tTrain_loss : 3.717857 / 3.569458 / 0.074200\tValid_loss : 4.455561 / 3.904523 / 0.275519\tNo Saved\n",
      "Epoch : 56\tTrain_loss : 3.690695 / 3.531589 / 0.079553\tValid_loss : 4.458428 / 3.904803 / 0.276813\tNo Saved\n",
      "Epoch : 57\tTrain_loss : 3.730209 / 3.548378 / 0.090915\tValid_loss : 4.564962 / 3.911901 / 0.326530\tNo Saved\n",
      "Epoch : 58\tTrain_loss : 3.799301 / 3.555603 / 0.121849\tValid_loss : 4.406564 / 3.899022 / 0.253771\tSaved\n",
      "Epoch : 59\tTrain_loss : 3.721767 / 3.533492 / 0.094138\tValid_loss : 4.430507 / 3.905997 / 0.262255\tNo Saved\n",
      "Epoch : 60\tTrain_loss : 3.800544 / 3.524022 / 0.138261\tValid_loss : 4.479368 / 3.907603 / 0.285882\tNo Saved\n",
      "Epoch : 61\tTrain_loss : 3.730349 / 3.524254 / 0.103047\tValid_loss : 4.514718 / 3.916235 / 0.299242\tNo Saved\n",
      "Epoch : 62\tTrain_loss : 3.723077 / 3.491793 / 0.115642\tValid_loss : 4.551226 / 3.910162 / 0.320532\tNo Saved\n",
      "Epoch : 63\tTrain_loss : 3.865899 / 3.519232 / 0.173334\tValid_loss : 4.426543 / 3.918381 / 0.254081\tNo Saved\n",
      "Epoch : 64\tTrain_loss : 3.667753 / 3.495965 / 0.085894\tValid_loss : 4.476854 / 3.913877 / 0.281488\tNo Saved\n",
      "Epoch : 65\tTrain_loss : 3.718088 / 3.491778 / 0.113155\tValid_loss : 4.410489 / 3.909928 / 0.250281\tNo Saved\n",
      "Epoch : 66\tTrain_loss : 3.859861 / 3.553872 / 0.152995\tValid_loss : 4.494694 / 3.902049 / 0.296322\tNo Saved\n",
      "Epoch : 67\tTrain_loss : 3.679106 / 3.516581 / 0.081262\tValid_loss : 4.522761 / 3.893247 / 0.314757\tNo Saved\n",
      "Epoch : 68\tTrain_loss : 3.717253 / 3.546351 / 0.085451\tValid_loss : 4.547930 / 3.900493 / 0.323719\tNo Saved\n",
      "Epoch : 69\tTrain_loss : 3.652571 / 3.506055 / 0.073258\tValid_loss : 4.464676 / 3.888580 / 0.288048\tNo Saved\n",
      "Epoch : 70\tTrain_loss : 3.775497 / 3.500202 / 0.137648\tValid_loss : 4.410414 / 3.895521 / 0.257447\tNo Saved\n",
      "Epoch : 71\tTrain_loss : 3.742495 / 3.473765 / 0.134365\tValid_loss : 4.429263 / 3.887655 / 0.270804\tNo Saved\n",
      "Epoch : 72\tTrain_loss : 3.717547 / 3.530010 / 0.093769\tValid_loss : 4.464757 / 3.908744 / 0.278007\tNo Saved\n",
      "Epoch : 73\tTrain_loss : 3.755806 / 3.457995 / 0.148905\tValid_loss : 4.518331 / 3.903782 / 0.307274\tNo Saved\n",
      "Epoch : 74\tTrain_loss : 3.654915 / 3.502312 / 0.076302\tValid_loss : 4.485230 / 3.901719 / 0.291755\tNo Saved\n",
      "Epoch : 75\tTrain_loss : 3.687020 / 3.480682 / 0.103169\tValid_loss : 4.458592 / 3.890524 / 0.284034\tNo Saved\n",
      "Epoch : 76\tTrain_loss : 3.725925 / 3.514994 / 0.105466\tValid_loss : 4.509506 / 3.883999 / 0.312753\tNo Saved\n",
      "Epoch : 77\tTrain_loss : 3.639437 / 3.483513 / 0.077962\tValid_loss : 4.524977 / 3.893665 / 0.315656\tNo Saved\n",
      "Epoch : 78\tTrain_loss : 3.713017 / 3.461913 / 0.125552\tValid_loss : 4.520209 / 3.913580 / 0.303314\tNo Saved\n",
      "Epoch : 79\tTrain_loss : 3.639385 / 3.470518 / 0.084434\tValid_loss : 4.453382 / 3.904174 / 0.274604\tNo Saved\n",
      "Epoch : 80\tTrain_loss : 3.660326 / 3.488246 / 0.086040\tValid_loss : 4.529647 / 3.899893 / 0.314877\tNo Saved\n",
      "Epoch : 81\tTrain_loss : 3.629632 / 3.482372 / 0.073630\tValid_loss : 4.467171 / 3.890771 / 0.288200\tNo Saved\n",
      "Epoch : 82\tTrain_loss : 3.638315 / 3.480081 / 0.079117\tValid_loss : 4.425204 / 3.887932 / 0.268636\tNo Saved\n",
      "Epoch : 83\tTrain_loss : 3.635800 / 3.466628 / 0.084586\tValid_loss : 4.469233 / 3.896904 / 0.286164\tNo Saved\n",
      "Epoch : 84\tTrain_loss : 3.750384 / 3.444079 / 0.153153\tValid_loss : 4.555880 / 3.912531 / 0.321675\tNo Saved\n",
      "Epoch : 85\tTrain_loss : 3.898660 / 3.459008 / 0.219826\tValid_loss : 4.353919 / 3.907475 / 0.223222\tSaved\n",
      "Epoch : 86\tTrain_loss : 3.710988 / 3.498296 / 0.106346\tValid_loss : 4.320947 / 3.903431 / 0.208758\tSaved\n",
      "Epoch : 87\tTrain_loss : 3.757807 / 3.464654 / 0.146576\tValid_loss : 4.498372 / 3.890947 / 0.303713\tNo Saved\n",
      "Epoch : 88\tTrain_loss : 3.787665 / 3.473610 / 0.157027\tValid_loss : 4.374175 / 3.885905 / 0.244135\tNo Saved\n",
      "Epoch : 89\tTrain_loss : 3.702782 / 3.479882 / 0.111450\tValid_loss : 4.402207 / 3.901798 / 0.250204\tNo Saved\n",
      "Epoch : 90\tTrain_loss : 3.688700 / 3.533684 / 0.077508\tValid_loss : 4.427226 / 3.897189 / 0.265018\tNo Saved\n",
      "Epoch : 91\tTrain_loss : 3.660904 / 3.498086 / 0.081409\tValid_loss : 4.376287 / 3.912143 / 0.232072\tNo Saved\n",
      "Epoch : 92\tTrain_loss : 3.634521 / 3.463312 / 0.085604\tValid_loss : 4.375018 / 3.904565 / 0.235226\tNo Saved\n",
      "Epoch : 93\tTrain_loss : 3.645174 / 3.441075 / 0.102049\tValid_loss : 4.406199 / 3.911769 / 0.247215\tNo Saved\n",
      "Epoch : 94\tTrain_loss : 3.612115 / 3.464761 / 0.073677\tValid_loss : 4.456608 / 3.917431 / 0.269589\tNo Saved\n",
      "Epoch : 95\tTrain_loss : 3.639972 / 3.469622 / 0.085175\tValid_loss : 4.389030 / 3.898363 / 0.245334\tNo Saved\n",
      "Epoch : 96\tTrain_loss : 3.741179 / 3.449976 / 0.145601\tValid_loss : 4.434847 / 3.916002 / 0.259423\tNo Saved\n",
      "Epoch : 97\tTrain_loss : 3.582991 / 3.451055 / 0.065968\tValid_loss : 4.541314 / 3.897745 / 0.321784\tNo Saved\n",
      "Epoch : 98\tTrain_loss : 3.653196 / 3.462154 / 0.095521\tValid_loss : 4.441217 / 3.911065 / 0.265076\tNo Saved\n",
      "Epoch : 99\tTrain_loss : 3.675374 / 3.463425 / 0.105975\tValid_loss : 4.451665 / 3.916200 / 0.267732\tNo Saved\n",
      "Epoch : 100\tTrain_loss : 3.703959 / 3.439403 / 0.132278\tValid_loss : 4.445428 / 3.917014 / 0.264207\tNo Saved\n",
      "Epoch : 101\tTrain_loss : 3.607111 / 3.461298 / 0.072907\tValid_loss : 4.397702 / 3.895430 / 0.251136\tNo Saved\n",
      "Epoch : 102\tTrain_loss : 3.650601 / 3.422530 / 0.114036\tValid_loss : 4.431387 / 3.893846 / 0.268771\tNo Saved\n",
      "Epoch : 103\tTrain_loss : 3.608402 / 3.433392 / 0.087505\tValid_loss : 4.434659 / 3.904253 / 0.265203\tNo Saved\n",
      "Epoch : 104\tTrain_loss : 3.652053 / 3.460892 / 0.095580\tValid_loss : 4.393245 / 3.912964 / 0.240140\tNo Saved\n",
      "Epoch : 105\tTrain_loss : 3.607617 / 3.454681 / 0.076468\tValid_loss : 4.469692 / 3.901760 / 0.283966\tNo Saved\n",
      "Epoch : 106\tTrain_loss : 3.614638 / 3.454269 / 0.080184\tValid_loss : 4.422809 / 3.913774 / 0.254518\tNo Saved\n",
      "Epoch : 107\tTrain_loss : 3.636526 / 3.438593 / 0.098967\tValid_loss : 4.387226 / 3.911422 / 0.237902\tNo Saved\n",
      "Epoch : 108\tTrain_loss : 3.648969 / 3.477368 / 0.085801\tValid_loss : 4.414031 / 3.907549 / 0.253241\tNo Saved\n",
      "Epoch : 109\tTrain_loss : 3.668657 / 3.419947 / 0.124355\tValid_loss : 4.417611 / 3.905487 / 0.256062\tNo Saved\n",
      "Epoch : 110\tTrain_loss : 3.762515 / 3.464012 / 0.149252\tValid_loss : 4.425775 / 3.913136 / 0.256320\tNo Saved\n",
      "Epoch : 111\tTrain_loss : 3.800941 / 3.429531 / 0.185705\tValid_loss : 4.445600 / 3.925267 / 0.260166\tNo Saved\n",
      "Epoch : 112\tTrain_loss : 3.571512 / 3.433944 / 0.068784\tValid_loss : 4.403554 / 3.912315 / 0.245620\tNo Saved\n",
      "Epoch : 113\tTrain_loss : 3.676840 / 3.437824 / 0.119508\tValid_loss : 4.413621 / 3.905719 / 0.253951\tNo Saved\n",
      "Epoch : 114\tTrain_loss : 3.584545 / 3.425925 / 0.079310\tValid_loss : 4.413919 / 3.915815 / 0.249052\tNo Saved\n",
      "Epoch : 115\tTrain_loss : 3.599688 / 3.435203 / 0.082242\tValid_loss : 4.362809 / 3.904483 / 0.229163\tNo Saved\n",
      "Epoch : 116\tTrain_loss : 3.609157 / 3.430185 / 0.089486\tValid_loss : 4.396365 / 3.905010 / 0.245677\tNo Saved\n",
      "Epoch : 117\tTrain_loss : 3.599956 / 3.459821 / 0.070068\tValid_loss : 4.438104 / 3.910092 / 0.264006\tNo Saved\n",
      "Epoch : 118\tTrain_loss : 3.666179 / 3.440896 / 0.112641\tValid_loss : 4.451145 / 3.913629 / 0.268758\tNo Saved\n",
      "Epoch : 119\tTrain_loss : 3.586587 / 3.426582 / 0.080003\tValid_loss : 4.381628 / 3.908190 / 0.236719\tNo Saved\n",
      "Epoch : 120\tTrain_loss : 3.550440 / 3.402646 / 0.073897\tValid_loss : 4.388510 / 3.914023 / 0.237243\tNo Saved\n",
      "Epoch : 121\tTrain_loss : 3.551636 / 3.420136 / 0.065750\tValid_loss : 4.339741 / 3.923380 / 0.208180\tNo Saved\n",
      "Epoch : 122\tTrain_loss : 3.600803 / 3.426876 / 0.086963\tValid_loss : 4.318361 / 3.894255 / 0.212053\tSaved\n",
      "Epoch : 123\tTrain_loss : 3.540809 / 3.416670 / 0.062070\tValid_loss : 4.305374 / 3.907347 / 0.199014\tSaved\n",
      "Epoch : 124\tTrain_loss : 3.561996 / 3.372535 / 0.094730\tValid_loss : 4.369464 / 3.906313 / 0.231576\tNo Saved\n",
      "Epoch : 125\tTrain_loss : 3.608633 / 3.408490 / 0.100072\tValid_loss : 4.405494 / 3.911083 / 0.247205\tNo Saved\n",
      "Epoch : 126\tTrain_loss : 3.605423 / 3.465223 / 0.070100\tValid_loss : 4.407308 / 3.914945 / 0.246181\tNo Saved\n",
      "Epoch : 127\tTrain_loss : 3.579451 / 3.411712 / 0.083869\tValid_loss : 4.441538 / 3.921962 / 0.259788\tNo Saved\n",
      "Epoch : 128\tTrain_loss : 3.707373 / 3.438956 / 0.134208\tValid_loss : 4.391504 / 3.914754 / 0.238375\tNo Saved\n",
      "Epoch : 129\tTrain_loss : 3.607857 / 3.415652 / 0.096102\tValid_loss : 4.499499 / 3.902686 / 0.298406\tNo Saved\n",
      "Epoch : 130\tTrain_loss : 3.606391 / 3.427387 / 0.089502\tValid_loss : 4.466833 / 3.925652 / 0.270590\tNo Saved\n",
      "Epoch : 131\tTrain_loss : 3.570546 / 3.430041 / 0.070253\tValid_loss : 4.420816 / 3.931597 / 0.244610\tNo Saved\n",
      "Epoch : 132\tTrain_loss : 3.632540 / 3.450862 / 0.090839\tValid_loss : 4.410283 / 3.922827 / 0.243728\tNo Saved\n",
      "Epoch : 133\tTrain_loss : 3.608246 / 3.418407 / 0.094920\tValid_loss : 4.415385 / 3.924924 / 0.245231\tNo Saved\n",
      "Epoch : 134\tTrain_loss : 3.626485 / 3.451452 / 0.087516\tValid_loss : 4.428490 / 3.910995 / 0.258747\tNo Saved\n",
      "Epoch : 135\tTrain_loss : 3.574773 / 3.437441 / 0.068666\tValid_loss : 4.347905 / 3.906667 / 0.220619\tNo Saved\n",
      "Epoch : 136\tTrain_loss : 3.659293 / 3.437331 / 0.110981\tValid_loss : 4.379079 / 3.915294 / 0.231893\tNo Saved\n",
      "Epoch : 137\tTrain_loss : 3.582325 / 3.417210 / 0.082558\tValid_loss : 4.344928 / 3.917769 / 0.213580\tNo Saved\n",
      "Epoch : 138\tTrain_loss : 3.684730 / 3.403616 / 0.140557\tValid_loss : 4.564702 / 3.921491 / 0.321605\tNo Saved\n",
      "Epoch : 139\tTrain_loss : 3.640537 / 3.439701 / 0.100418\tValid_loss : 4.460274 / 3.924698 / 0.267788\tNo Saved\n",
      "Epoch : 140\tTrain_loss : 3.557813 / 3.427757 / 0.065028\tValid_loss : 4.406906 / 3.931255 / 0.237825\tNo Saved\n",
      "Epoch : 141\tTrain_loss : 3.557918 / 3.406622 / 0.075648\tValid_loss : 4.380315 / 3.921242 / 0.229536\tNo Saved\n",
      "Epoch : 142\tTrain_loss : 3.554788 / 3.401979 / 0.076405\tValid_loss : 4.326435 / 3.923280 / 0.201578\tNo Saved\n",
      "Epoch : 143\tTrain_loss : 3.668853 / 3.403476 / 0.132689\tValid_loss : 4.318747 / 3.927012 / 0.195868\tNo Saved\n",
      "Epoch : 144\tTrain_loss : 3.625855 / 3.433276 / 0.096289\tValid_loss : 4.356783 / 3.934289 / 0.211247\tNo Saved\n",
      "Epoch : 145\tTrain_loss : 3.553997 / 3.420624 / 0.066686\tValid_loss : 4.339343 / 3.942416 / 0.198464\tNo Saved\n",
      "Epoch : 146\tTrain_loss : 3.522141 / 3.386441 / 0.067850\tValid_loss : 4.377440 / 3.932835 / 0.222303\tNo Saved\n",
      "Epoch : 147\tTrain_loss : 3.650200 / 3.389160 / 0.130520\tValid_loss : 4.373974 / 3.910788 / 0.231593\tNo Saved\n",
      "Epoch : 148\tTrain_loss : 3.690437 / 3.415426 / 0.137506\tValid_loss : 4.565781 / 3.909505 / 0.328138\tNo Saved\n",
      "Epoch : 149\tTrain_loss : 3.701200 / 3.398817 / 0.151191\tValid_loss : 4.395332 / 3.936747 / 0.229292\tNo Saved\n",
      "Epoch : 150\tTrain_loss : 3.594396 / 3.445025 / 0.074685\tValid_loss : 4.355931 / 3.928885 / 0.213523\tNo Saved\n",
      "Epoch : 151\tTrain_loss : 3.683540 / 3.396195 / 0.143672\tValid_loss : 4.336091 / 3.925400 / 0.205345\tNo Saved\n",
      "Epoch : 152\tTrain_loss : 3.558315 / 3.395120 / 0.081598\tValid_loss : 4.317486 / 3.936166 / 0.190660\tNo Saved\n",
      "Epoch : 153\tTrain_loss : 3.659238 / 3.389759 / 0.134740\tValid_loss : 4.383035 / 3.932018 / 0.225509\tNo Saved\n",
      "Epoch : 154\tTrain_loss : 3.569023 / 3.399696 / 0.084663\tValid_loss : 4.314153 / 3.936347 / 0.188903\tNo Saved\n",
      "Epoch : 155\tTrain_loss : 3.578380 / 3.454718 / 0.061831\tValid_loss : 4.351357 / 3.929291 / 0.211033\tNo Saved\n",
      "Epoch : 156\tTrain_loss : 3.557056 / 3.427905 / 0.064575\tValid_loss : 4.347192 / 3.945468 / 0.200862\tNo Saved\n",
      "Epoch : 157\tTrain_loss : 3.606179 / 3.396620 / 0.104779\tValid_loss : 4.343347 / 3.936351 / 0.203498\tNo Saved\n",
      "Epoch : 158\tTrain_loss : 3.592486 / 3.396542 / 0.097972\tValid_loss : 4.413896 / 3.935451 / 0.239223\tNo Saved\n",
      "Epoch : 159\tTrain_loss : 3.600627 / 3.330177 / 0.135225\tValid_loss : 4.379684 / 3.940754 / 0.219465\tNo Saved\n",
      "Epoch : 160\tTrain_loss : 3.622611 / 3.339588 / 0.141512\tValid_loss : 4.322130 / 3.946682 / 0.187724\tNo Saved\n",
      "Epoch : 161\tTrain_loss : 3.515819 / 3.365465 / 0.075177\tValid_loss : 4.421928 / 3.939139 / 0.241395\tNo Saved\n",
      "Epoch : 162\tTrain_loss : 3.489590 / 3.333904 / 0.077843\tValid_loss : 4.396953 / 3.932018 / 0.232468\tNo Saved\n",
      "Epoch : 163\tTrain_loss : 3.511401 / 3.376015 / 0.067693\tValid_loss : 4.355393 / 3.928897 / 0.213248\tNo Saved\n",
      "Epoch : 164\tTrain_loss : 3.622539 / 3.359213 / 0.131663\tValid_loss : 4.292799 / 3.948491 / 0.172154\tSaved\n",
      "Epoch : 165\tTrain_loss : 3.566634 / 3.405393 / 0.080621\tValid_loss : 4.288781 / 3.955374 / 0.166703\tSaved\n",
      "Epoch : 166\tTrain_loss : 3.558565 / 3.407773 / 0.075396\tValid_loss : 4.405845 / 3.939268 / 0.233288\tNo Saved\n",
      "Epoch : 167\tTrain_loss : 3.567281 / 3.364413 / 0.101434\tValid_loss : 4.407737 / 3.935781 / 0.235978\tNo Saved\n",
      "Epoch : 168\tTrain_loss : 3.489751 / 3.358288 / 0.065731\tValid_loss : 4.372927 / 3.940299 / 0.216314\tNo Saved\n",
      "Epoch : 169\tTrain_loss : 3.516049 / 3.388181 / 0.063934\tValid_loss : 4.355964 / 3.954037 / 0.200963\tNo Saved\n",
      "Epoch : 170\tTrain_loss : 3.599584 / 3.399673 / 0.099955\tValid_loss : 4.466785 / 3.950946 / 0.257920\tNo Saved\n",
      "Epoch : 171\tTrain_loss : 3.516739 / 3.340246 / 0.088247\tValid_loss : 4.398693 / 3.943427 / 0.227633\tNo Saved\n",
      "Epoch : 172\tTrain_loss : 3.653466 / 3.401419 / 0.126024\tValid_loss : 4.379339 / 3.934392 / 0.222473\tNo Saved\n",
      "Epoch : 173\tTrain_loss : 3.566511 / 3.403910 / 0.081300\tValid_loss : 4.386011 / 3.946957 / 0.219527\tNo Saved\n",
      "Epoch : 174\tTrain_loss : 3.540179 / 3.364713 / 0.087733\tValid_loss : 4.373668 / 3.930114 / 0.221777\tNo Saved\n",
      "Epoch : 175\tTrain_loss : 3.607211 / 3.401666 / 0.102772\tValid_loss : 4.417616 / 3.948157 / 0.234729\tNo Saved\n",
      "Epoch : 176\tTrain_loss : 3.532493 / 3.364368 / 0.084063\tValid_loss : 4.388507 / 3.934420 / 0.227044\tNo Saved\n",
      "Epoch : 177\tTrain_loss : 3.536506 / 3.356854 / 0.089826\tValid_loss : 4.387387 / 3.931600 / 0.227893\tNo Saved\n",
      "Epoch : 178\tTrain_loss : 3.719558 / 3.379126 / 0.170216\tValid_loss : 4.420027 / 3.934400 / 0.242814\tNo Saved\n",
      "Epoch : 179\tTrain_loss : 3.553014 / 3.359987 / 0.096514\tValid_loss : 4.453428 / 3.948347 / 0.252540\tNo Saved\n",
      "Epoch : 180\tTrain_loss : 3.527912 / 3.368641 / 0.079636\tValid_loss : 4.452545 / 3.949839 / 0.251353\tNo Saved\n",
      "Epoch : 181\tTrain_loss : 3.499008 / 3.368111 / 0.065449\tValid_loss : 4.393235 / 3.950537 / 0.221349\tNo Saved\n",
      "Epoch : 182\tTrain_loss : 3.497623 / 3.337259 / 0.080182\tValid_loss : 4.426058 / 3.933148 / 0.246455\tNo Saved\n",
      "Epoch : 183\tTrain_loss : 3.548707 / 3.374967 / 0.086870\tValid_loss : 4.469839 / 3.950433 / 0.259703\tNo Saved\n",
      "Epoch : 184\tTrain_loss : 3.507796 / 3.365505 / 0.071146\tValid_loss : 4.475931 / 3.942033 / 0.266949\tNo Saved\n",
      "Epoch : 185\tTrain_loss : 3.468480 / 3.352027 / 0.058226\tValid_loss : 4.391638 / 3.931649 / 0.229994\tNo Saved\n",
      "Epoch : 186\tTrain_loss : 3.519188 / 3.342241 / 0.088474\tValid_loss : 4.347077 / 3.932285 / 0.207396\tNo Saved\n",
      "Epoch : 187\tTrain_loss : 3.532319 / 3.354538 / 0.088890\tValid_loss : 4.441059 / 3.944504 / 0.248278\tNo Saved\n",
      "Epoch : 188\tTrain_loss : 3.580302 / 3.328116 / 0.126093\tValid_loss : 4.395712 / 3.965531 / 0.215091\tNo Saved\n",
      "Epoch : 189\tTrain_loss : 3.569985 / 3.331430 / 0.119277\tValid_loss : 4.368324 / 3.943406 / 0.212459\tNo Saved\n",
      "Epoch : 190\tTrain_loss : 3.540525 / 3.359804 / 0.090360\tValid_loss : 4.372334 / 3.962722 / 0.204806\tNo Saved\n",
      "Epoch : 191\tTrain_loss : 3.501222 / 3.352069 / 0.074577\tValid_loss : 4.434567 / 3.960001 / 0.237283\tNo Saved\n",
      "Epoch : 192\tTrain_loss : 3.553669 / 3.375100 / 0.089284\tValid_loss : 4.384633 / 3.951206 / 0.216713\tNo Saved\n",
      "Epoch : 193\tTrain_loss : 3.523431 / 3.342964 / 0.090233\tValid_loss : 4.441890 / 3.959869 / 0.241010\tNo Saved\n",
      "Epoch : 194\tTrain_loss : 3.488799 / 3.319345 / 0.084727\tValid_loss : 4.424019 / 3.952818 / 0.235600\tNo Saved\n",
      "Epoch : 195\tTrain_loss : 3.505201 / 3.347257 / 0.078972\tValid_loss : 4.402589 / 3.960674 / 0.220957\tNo Saved\n",
      "Epoch : 196\tTrain_loss : 3.466966 / 3.324062 / 0.071452\tValid_loss : 4.293174 / 3.942050 / 0.175562\tNo Saved\n",
      "Epoch : 197\tTrain_loss : 3.488319 / 3.330015 / 0.079152\tValid_loss : 4.236445 / 3.960254 / 0.138096\tSaved\n",
      "Epoch : 198\tTrain_loss : 3.463039 / 3.350089 / 0.056475\tValid_loss : 4.279054 / 3.951080 / 0.163987\tNo Saved\n",
      "Epoch : 199\tTrain_loss : 3.583190 / 3.371766 / 0.105712\tValid_loss : 4.323290 / 3.963969 / 0.179661\tNo Saved\n",
      "Epoch : 200\tTrain_loss : 3.510093 / 3.371801 / 0.069146\tValid_loss : 4.481495 / 3.965932 / 0.257782\tNo Saved\n",
      "Training Model 3 of 3 is Completed...\n",
      "Train is Ended, Do Test\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import os, math\n",
    "import config\n",
    "\n",
    "from model_functions import build_model, run_session\n",
    "\n",
    "os.makedirs(config.dir_ckpt , exist_ok=True)\n",
    "\n",
    "raw_df = pd.read_csv('./data/dataset_kor//Kor_Train_(12.1~17.6).csv', engine='python')\n",
    "raw_df = raw_df[config.test_cols]\n",
    "\n",
    "for key in config.kv_map.keys():\n",
    "    raw_df[key] = raw_df[key].apply(lambda x: config.kv_map[key][x])\n",
    "\n",
    "for mdl_num in range(1,4):\n",
    "    if mdl_num == 1:\n",
    "        np.random.seed(seed=1000)\n",
    "        shuffle_idx = np.random.rand(len(raw_df)) \n",
    "        train_df = raw_df[shuffle_idx<= 0.85]\n",
    "        valid_df = raw_df[shuffle_idx > 0.85]\n",
    "\n",
    "    elif mdl_num == 2:\n",
    "        np.random.seed(seed=2000)\n",
    "        shuffle_idx = np.random.rand(len(raw_df)) \n",
    "        train_df = raw_df[shuffle_idx<= 0.85]\n",
    "        valid_df = raw_df[shuffle_idx > 0.85]\n",
    "\n",
    "    else:\n",
    "        train_df = raw_df[:config.train_size]\n",
    "        valid_df = raw_df[config.train_size:]\n",
    "    \n",
    "    \n",
    "    config.path_ckpt = os.path.join(config.dir_ckpt, 'best{}.ckpt'.format(mdl_num))\n",
    "\n",
    "    train_df_cate = train_df.loc[:,config.cate_cols]\n",
    "    train_df_cont = train_df.loc[:,config.cont_cols]\n",
    "\n",
    "    valid_df_cate = valid_df.loc[:,config.cate_cols]\n",
    "    valid_df_cont = valid_df.loc[:,config.cont_cols]\n",
    "\n",
    "    np.random.seed(seed=9)\n",
    "    config.vaild_drop_mask = np.random.rand(valid_df_cate.values.shape[0], valid_df_cate.values.shape[1])>(1- config.keep_prop)\n",
    "    config.vaild_cont_mask = np.random.rand(valid_df_cont.values.shape[0], valid_df_cont.values.shape[1])<(1- config.keep_prop)\n",
    "\n",
    "    np.random.seed(seed=19)\n",
    "    config.vaild_test_drop_mask = np.random.rand(valid_df_cate.values.shape[0], valid_df_cate.values.shape[1])>(1- config.keep_prop)\n",
    "    config.vaild_test_cont_mask = np.random.rand(valid_df_cont.values.shape[0], valid_df_cont.values.shape[1])<(1- config.keep_prop)\n",
    "\n",
    "    train_step = math.ceil(len(train_df)/ config.batch_size)\n",
    "    valid_step = math.ceil(len(valid_df)/ config.batch_size)\n",
    "    print(\"Data is Ready...\")\n",
    "\n",
    "    mdl = build_model(config)\n",
    "    print(\"Model {} is built...\".format(mdl_num))\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # run session\n",
    "    with tf.Session() as sess:\n",
    "        tf.set_random_seed(seed=1991)\n",
    "        np.random.seed(seed=1991)\n",
    "        sess.run(init)\n",
    "    #     saver.restore(sess, config.path_ckpt)\n",
    "        min_val_loss = 9999\n",
    "        print(\"Model {} is training\".format(mdl_num))\n",
    "        for epoch in range(1, config.epochs+1):\n",
    "            #train\n",
    "            trn_total_loss_ = run_session(sess, train_step, [train_df_cate, train_df_cont], config, mdl, mode=1)\n",
    "            \n",
    "            #valid\n",
    "            val_total_loss_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=2)\n",
    "            \n",
    "            if config.verbose:\n",
    "                print(\"Epoch : {}\".format(epoch), end='\\t')\n",
    "                print(\"Train_loss : {:.6f} / {:.6f} / {:.6f}\".format(trn_total_loss_[0], trn_total_loss_[1], trn_total_loss_[2]), end = '\\t')\n",
    "                print(\"Valid_loss : {:.6f} / {:.6f} / {:.6f}\".format(val_total_loss_[0], val_total_loss_[1], val_total_loss_[2]), end = '\\t')\n",
    "            \n",
    "            #monitor\n",
    "            if val_total_loss_[0] < min_val_loss:\n",
    "                saver.save(sess, config.path_ckpt)\n",
    "                min_val_loss = val_total_loss_[0]\n",
    "                if config.verbose:\n",
    "                    print(\"Saved\")\n",
    "            else:\n",
    "                if config.verbose:\n",
    "                    print(\"No Saved\")\n",
    "        print(\"Training Model {} of 3 is Completed...\".format(mdl_num))\n",
    "        \n",
    "print(\"Train is Ended, Do Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(preds_cate_, preds_cont_):\n",
    "    #out\n",
    "    print(\"Exproting...\")\n",
    "    #cliping\n",
    "    preds_cont_[preds_cont_<0] = 0.0\n",
    "\n",
    "    # Categorical Vals Restore\n",
    "    pred_args = []\n",
    "    for p_ in preds_cate_:\n",
    "        start_idx = 0\n",
    "        pred_arg = []\n",
    "        for kl in config.cate_lens:\n",
    "            pred_arg.append(np.argmax(p_[start_idx: start_idx+kl]))\n",
    "            start_idx += kl\n",
    "        pred_args.append(pred_arg)\n",
    "    pred_args_np = np.array(pred_args)   \n",
    "\n",
    "\n",
    "    total_cell = ((config.vaild_test_drop_mask - 1) * -1)\n",
    "\n",
    "    pred_cells = (pred_args_np * total_cell)\n",
    "\n",
    "    true_cells = valid_df_cate.values\n",
    "     \n",
    "    cate_score = (pred_cells == true_cells).sum() / total_cell.sum()\n",
    "    nume_score = (np.exp(-np.square(preds_cont_ - valid_df_cont.values)) * config.vaild_test_cont_mask).sum() / config.vaild_test_cont_mask.sum()\n",
    "    print('categorical_score:', cate_score)\n",
    "    print('numeric_score:', nume_score)\n",
    "    print('total_score', cate_score + nume_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best1.ckpt\n",
      "Exproting...\n",
      "categorical_score: 0.6256122249069418\n",
      "numeric_score: 0.940713424046426\n",
      "total_score 1.566325648953368\n",
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best2.ckpt\n",
      "Exproting...\n",
      "categorical_score: 0.6329915757852805\n",
      "numeric_score: 0.939144471430407\n",
      "total_score 1.5721360472156876\n",
      "INFO:tensorflow:Restoring parameters from .\\ckpt\\best3.ckpt\n",
      "Exproting...\n",
      "categorical_score: 0.5981192450858748\n",
      "numeric_score: 0.9414339235909605\n",
      "total_score 1.5395531686768353\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(\"Predicting...\")\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best1.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=3)\n",
    "\n",
    "    preds_cate_1 = np.concatenate(preds_cate_)\n",
    "    preds_cont_1 = np.concatenate(preds_cont_)\n",
    "    eval_score(preds_cate_1, preds_cont_1)\n",
    "\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best2.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=3)\n",
    "\n",
    "    preds_cate_2 = np.concatenate(preds_cate_)\n",
    "    preds_cont_2 = np.concatenate(preds_cont_)\n",
    "    eval_score(preds_cate_2, preds_cont_2)\n",
    "\n",
    "    saver.restore(sess, '.\\\\ckpt\\\\best3.ckpt')\n",
    "    preds_cate_, preds_cont_ = run_session(sess, valid_step, [valid_df_cate, valid_df_cont], config, mdl, mode=3)\n",
    "\n",
    "    preds_cate_3 = np.concatenate(preds_cate_)\n",
    "    preds_cont_3 = np.concatenate(preds_cont_)\n",
    "    eval_score(preds_cate_3, preds_cont_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
